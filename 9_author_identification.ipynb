{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author Identification using Natural Language Processing\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "The goal is to identify the author of a text from a given list of possible authors using computational stylometry and machine learning techniques.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Preprocess text data** for author identification tasks\n",
    "2. **Extract stylometric features** that capture writing style\n",
    "3. **Apply various text vectorization techniques** (TF-IDF, Count Vectorizer, Word2Vec)\n",
    "4. **Build classification models** for author identification\n",
    "5. **Evaluate and compare different approaches** for authorship attribution\n",
    "6. **Understand computational stylometry** and its applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Stylometry\n",
    "\n",
    "**Stylometry** is the quantitative study of literary style through computational methods. It's based on the observation that authors tend to write in relatively consistent, recognizable, and unique ways.\n",
    "\n",
    "### Key Stylistic Elements:\n",
    "- **Vocabulary richness**: Some authors use rich vocabulary, others prefer simplicity\n",
    "- **Sentence structure**: Preference for short vs. long sentences\n",
    "- **Punctuation patterns**: Unique usage of semicolons, dashes, etc.\n",
    "- **Word frequency**: Characteristic use of function words\n",
    "- **Syntactic patterns**: Grammar and sentence construction preferences\n",
    "\n",
    "### Applications:\n",
    "- Literary analysis and attribution\n",
    "- Forensic linguistics\n",
    "- Plagiarism detection\n",
    "- Social media analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages",
    "!pip install numpy pandas matplotlib seaborn nltk scikit-learn torch tqdm textstat",
    "",
    "# Enable ipywidgets for Jupyter",
    "!jupyter nbextension enable --py widgetsnbextension",
    "",
    "# Download required NLTK data",
    "import nltk",
    "for item in ['gutenberg', 'punkt', 'stopwords', 'averaged_perceptron_tagger', 'wordnet']:",
    "    nltk.download(item, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Text processing\n",
    "from textstat import flesch_reading_ease, flesch_kincaid_grade\n",
    "import urllib.request\n",
    "from io import StringIO\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk_downloads = ['gutenberg', 'punkt', 'stopwords', 'averaged_perceptron_tagger', 'wordnet']\n",
    "for item in nltk_downloads:\n",
    "    try:\n",
    "        nltk.download(item, quiet=True)\n",
    "    except:\n",
    "        print(f\"Could not download {item}\")\n",
    "\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Collection and Preprocessing\n",
    "\n",
    "We'll work with classic authors whose works are available through Project Gutenberg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our authors and their works\n",
    "AUTHORS_DATA = {\n",
    "    'shakespeare': {\n",
    "        'name': 'William Shakespeare',\n",
    "        'gutenberg_files': ['shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'shakespeare-caesar.txt']\n",
    "    },\n",
    "    'austen': {\n",
    "        'name': 'Jane Austen', \n",
    "        'gutenberg_files': ['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt']\n",
    "    },\n",
    "    'chesterton': {\n",
    "        'name': 'G.K. Chesterton',\n",
    "        'gutenberg_files': ['chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Alternative authors with direct URLs for more variety\n",
    "ADDITIONAL_AUTHORS = {\n",
    "    'dickens': {\n",
    "        'name': 'Charles Dickens',\n",
    "        'url': 'https://www.gutenberg.org/files/98/98-0.txt',  # A Tale of Two Cities\n",
    "        'title': 'A Tale of Two Cities'\n",
    "    },\n",
    "    'twain': {\n",
    "        'name': 'Mark Twain',\n",
    "        'url': 'https://www.gutenberg.org/files/74/74-0.txt',   # Tom Sawyer\n",
    "        'title': 'The Adventures of Tom Sawyer'\n",
    "    },\n",
    "    'wilde': {\n",
    "        'name': 'Oscar Wilde',\n",
    "        'url': 'https://www.gutenberg.org/files/174/174-0.txt', # The Picture of Dorian Gray\n",
    "        'title': 'The Picture of Dorian Gray'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Authors available for analysis:\")\n",
    "for key, value in AUTHORS_DATA.items():\n",
    "    print(f\"- {value['name']} ({key})\")\n",
    "for key, value in ADDITIONAL_AUTHORS.items():\n",
    "    print(f\"- {value['name']} ({key}) - {value['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_text_from_url(url, encoding='utf-8'):\n",
    "    \"\"\"Download text from a URL\"\"\"\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text = response.read().decode(encoding, errors='ignore')\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_gutenberg_texts():\n",
    "    \"\"\"Load texts from NLTK Gutenberg corpus\"\"\"\n",
    "    texts = {}\n",
    "    \n",
    "    # Load NLTK Gutenberg texts\n",
    "    for author_key, author_data in AUTHORS_DATA.items():\n",
    "        author_texts = []\n",
    "        for file_id in author_data['gutenberg_files']:\n",
    "            try:\n",
    "                text = nltk.corpus.gutenberg.raw(file_id)\n",
    "                author_texts.append(text)\n",
    "            except:\n",
    "                print(f\"Could not load {file_id}\")\n",
    "        \n",
    "        if author_texts:\n",
    "            # Combine all texts for this author\n",
    "            combined_text = ' '.join(author_texts)\n",
    "            texts[author_key] = {\n",
    "                'name': author_data['name'],\n",
    "                'text': combined_text,\n",
    "                'source': 'gutenberg_corpus'\n",
    "            }\n",
    "    \n",
    "    # Load additional authors from URLs\n",
    "    for author_key, author_data in ADDITIONAL_AUTHORS.items():\n",
    "        print(f\"Downloading {author_data['name']} - {author_data['title']}...\")\n",
    "        text = download_text_from_url(author_data['url'])\n",
    "        if text:\n",
    "            texts[author_key] = {\n",
    "                'name': author_data['name'],\n",
    "                'text': text,\n",
    "                'title': author_data['title'],\n",
    "                'source': 'project_gutenberg_url'\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Failed to download text for {author_data['name']}\")\n",
    "    \n",
    "    return texts\n",
    "\n",
    "# Load all texts\n",
    "author_texts = load_gutenberg_texts()\n",
    "\n",
    "print(f\"\\nSuccessfully loaded texts for {len(author_texts)} authors:\")\n",
    "for key, data in author_texts.items():\n",
    "    text_length = len(data['text'])\n",
    "    print(f\"- {data['name']}: {text_length:,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Basic text cleaning\"\"\"\n",
    "    # Remove Project Gutenberg headers and footers\n",
    "    start_markers = ['*** START OF', '***START OF', 'START OF THE PROJECT']\n",
    "    end_markers = ['*** END OF', '***END OF', 'END OF THE PROJECT']\n",
    "    \n",
    "    # Find start\n",
    "    start_idx = 0\n",
    "    for marker in start_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1:\n",
    "            # Find the end of the line\n",
    "            line_end = text.find('\\n', idx)\n",
    "            if line_end != -1:\n",
    "                start_idx = line_end + 1\n",
    "            break\n",
    "    \n",
    "    # Find end\n",
    "    end_idx = len(text)\n",
    "    for marker in end_markers:\n",
    "        idx = text.rfind(marker)\n",
    "        if idx != -1:\n",
    "            end_idx = idx\n",
    "            break\n",
    "    \n",
    "    # Extract main text\n",
    "    cleaned_text = text[start_idx:end_idx]\n",
    "    \n",
    "    # Basic cleaning\n",
    "    cleaned_text = re.sub(r'\\n+', ' ', cleaned_text)  # Replace multiple newlines\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)   # Replace multiple spaces\n",
    "    cleaned_text = cleaned_text.strip()\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "def split_into_sentences(text, min_length=10):\n",
    "    \"\"\"Split text into sentences\"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    # Filter out very short sentences\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) >= min_length]\n",
    "    return sentences\n",
    "\n",
    "def split_into_paragraphs(text, min_length=50):\n",
    "    \"\"\"Split text into paragraphs\"\"\"\n",
    "    # Split by double newlines or significant breaks\n",
    "    paragraphs = re.split(r'\\n\\s*\\n', text)\n",
    "    paragraphs = [p.strip() for p in paragraphs if len(p.strip()) >= min_length]\n",
    "    return paragraphs\n",
    "\n",
    "# Clean all texts\n",
    "print(\"Cleaning texts...\")\n",
    "for author_key in author_texts:\n",
    "    author_texts[author_key]['cleaned_text'] = clean_text(author_texts[author_key]['text'])\n",
    "    \n",
    "    # Basic statistics\n",
    "    text = author_texts[author_key]['cleaned_text']\n",
    "    sentences = split_into_sentences(text)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    author_texts[author_key]['sentences'] = sentences\n",
    "    author_texts[author_key]['words'] = words\n",
    "    author_texts[author_key]['num_sentences'] = len(sentences)\n",
    "    author_texts[author_key]['num_words'] = len(words)\n",
    "    \n",
    "    print(f\"{author_texts[author_key]['name']}:\")\n",
    "    print(f\"  - Sentences: {len(sentences):,}\")\n",
    "    print(f\"  - Words: {len(words):,}\")\n",
    "    print(f\"  - Avg words per sentence: {len(words)/len(sentences):.1f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Training Dataset\n",
    "\n",
    "We'll create a dataset where each sample is a text segment (sentence or paragraph) with its corresponding author label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(author_texts, segment_type='sentence', max_samples_per_author=1000):\n",
    "    \"\"\"Create a dataset for author classification\"\"\"\n",
    "    dataset = []\n",
    "    \n",
    "    for author_key, data in author_texts.items():\n",
    "        author_name = data['name']\n",
    "        text = data['cleaned_text']\n",
    "        \n",
    "        if segment_type == 'sentence':\n",
    "            segments = split_into_sentences(text, min_length=20)\n",
    "        elif segment_type == 'paragraph':\n",
    "            segments = split_into_paragraphs(text, min_length=100)\n",
    "        else:\n",
    "            # Fixed-length chunks\n",
    "            words = text.split()\n",
    "            chunk_size = 100  # words per chunk\n",
    "            segments = []\n",
    "            for i in range(0, len(words) - chunk_size, chunk_size//2):  # 50% overlap\n",
    "                chunk = ' '.join(words[i:i+chunk_size])\n",
    "                segments.append(chunk)\n",
    "        \n",
    "        # Limit samples per author for balanced dataset\n",
    "        if len(segments) > max_samples_per_author:\n",
    "            # Take random sample\n",
    "            import random\n",
    "            random.seed(42)\n",
    "            segments = random.sample(segments, max_samples_per_author)\n",
    "        \n",
    "        # Add to dataset\n",
    "        for segment in segments:\n",
    "            dataset.append({\n",
    "                'text': segment,\n",
    "                'author': author_key,\n",
    "                'author_name': author_name\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(dataset)\n",
    "\n",
    "# Create datasets with different granularities\n",
    "sentence_dataset = create_dataset(author_texts, 'sentence', max_samples_per_author=800)\n",
    "paragraph_dataset = create_dataset(author_texts, 'paragraph', max_samples_per_author=200)\n",
    "chunk_dataset = create_dataset(author_texts, 'chunk', max_samples_per_author=500)\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Sentence-based dataset: {len(sentence_dataset)} samples\")\n",
    "print(sentence_dataset['author_name'].value_counts())\n",
    "print()\n",
    "print(f\"Paragraph-based dataset: {len(paragraph_dataset)} samples\")\n",
    "print(paragraph_dataset['author_name'].value_counts())\n",
    "print()\n",
    "print(f\"Chunk-based dataset: {len(chunk_dataset)} samples\")\n",
    "print(chunk_dataset['author_name'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text_statistics(df):\n",
    "    \"\"\"Analyze basic text statistics\"\"\"\n",
    "    # Calculate statistics\n",
    "    df['text_length'] = df['text'].str.len()\n",
    "    df['word_count'] = df['text'].str.split().str.len()\n",
    "    df['sentence_count'] = df['text'].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
    "    df['avg_word_length'] = df['text'].apply(\n",
    "        lambda x: np.mean([len(word) for word in x.split() if word.isalpha()])\n",
    "    )\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Text length distribution\n",
    "    df.boxplot(column='text_length', by='author_name', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Text Length Distribution by Author')\n",
    "    axes[0,0].set_xlabel('Author')\n",
    "    \n",
    "    # Word count distribution\n",
    "    df.boxplot(column='word_count', by='author_name', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Word Count Distribution by Author')\n",
    "    axes[0,1].set_xlabel('Author')\n",
    "    \n",
    "    # Average word length\n",
    "    df.boxplot(column='avg_word_length', by='author_name', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Average Word Length by Author')\n",
    "    axes[1,0].set_xlabel('Author')\n",
    "    \n",
    "    # Sentence count (for longer texts)\n",
    "    if df['sentence_count'].max() > 1:\n",
    "        df.boxplot(column='sentence_count', by='author_name', ax=axes[1,1])\n",
    "        axes[1,1].set_title('Sentence Count by Author')\n",
    "        axes[1,1].set_xlabel('Author')\n",
    "    else:\n",
    "        axes[1,1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"Summary Statistics by Author:\")\n",
    "    summary = df.groupby('author_name')[['text_length', 'word_count', 'avg_word_length']].agg(['mean', 'std'])\n",
    "    print(summary.round(2))\n",
    "\n",
    "# Analyze sentence dataset\n",
    "print(\"=== Sentence-based Dataset Analysis ===\")\n",
    "analyze_text_statistics(sentence_dataset.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stylometric Feature Extraction\n",
    "\n",
    "Let's extract various stylometric features that capture different aspects of writing style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StylometricFeatureExtractor:\n",
    "    \"\"\"Extract various stylometric features from text\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "        \n",
    "    def extract_features(self, text):\n",
    "        \"\"\"Extract all stylometric features from text\"\"\"\n",
    "        features = {}\n",
    "        \n",
    "        # Basic length features\n",
    "        features.update(self._length_features(text))\n",
    "        \n",
    "        # Lexical features\n",
    "        features.update(self._lexical_features(text))\n",
    "        \n",
    "        # Syntactic features\n",
    "        features.update(self._syntactic_features(text))\n",
    "        \n",
    "        # Punctuation features\n",
    "        features.update(self._punctuation_features(text))\n",
    "        \n",
    "        # Readability features\n",
    "        features.update(self._readability_features(text))\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _length_features(self, text):\n",
    "        \"\"\"Extract length-based features\"\"\"\n",
    "        words = nltk.word_tokenize(text)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        \n",
    "        alpha_words = [w for w in words if w.isalpha()]\n",
    "        \n",
    "        features = {\n",
    "            'avg_word_length': np.mean([len(w) for w in alpha_words]) if alpha_words else 0,\n",
    "            'avg_sentence_length': len(words) / len(sentences) if sentences else 0,\n",
    "            'max_word_length': max([len(w) for w in alpha_words]) if alpha_words else 0,\n",
    "            'min_word_length': min([len(w) for w in alpha_words]) if alpha_words else 0,\n",
    "            'word_length_std': np.std([len(w) for w in alpha_words]) if alpha_words else 0\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _lexical_features(self, text):\n",
    "        \"\"\"Extract lexical diversity features\"\"\"\n",
    "        words = nltk.word_tokenize(text.lower())\n",
    "        alpha_words = [w for w in words if w.isalpha()]\n",
    "        \n",
    "        if not alpha_words:\n",
    "            return {\n",
    "                'type_token_ratio': 0,\n",
    "                'hapax_legomena_ratio': 0,\n",
    "                'simpson_index': 0,\n",
    "                'long_word_ratio': 0,\n",
    "                'stop_word_ratio': 0\n",
    "            }\n",
    "        \n",
    "        word_freq = Counter(alpha_words)\n",
    "        unique_words = len(word_freq)\n",
    "        total_words = len(alpha_words)\n",
    "        \n",
    "        # Type-Token Ratio (lexical diversity)\n",
    "        ttr = unique_words / total_words if total_words > 0 else 0\n",
    "        \n",
    "        # Hapax Legomena (words appearing exactly once)\n",
    "        hapax = sum(1 for count in word_freq.values() if count == 1)\n",
    "        hapax_ratio = hapax / unique_words if unique_words > 0 else 0\n",
    "        \n",
    "        # Simpson's Index (another diversity measure)\n",
    "        simpson = sum((count/total_words)**2 for count in word_freq.values())\n",
    "        \n",
    "        # Long words (> 6 characters)\n",
    "        long_words = sum(1 for w in alpha_words if len(w) > 6)\n",
    "        long_word_ratio = long_words / total_words\n",
    "        \n",
    "        # Stop word ratio\n",
    "        stop_words_count = sum(1 for w in alpha_words if w in self.stop_words)\n",
    "        stop_word_ratio = stop_words_count / total_words\n",
    "        \n",
    "        features = {\n",
    "            'type_token_ratio': ttr,\n",
    "            'hapax_legomena_ratio': hapax_ratio,\n",
    "            'simpson_index': simpson,\n",
    "            'long_word_ratio': long_word_ratio,\n",
    "            'stop_word_ratio': stop_word_ratio\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _syntactic_features(self, text):\n",
    "        \"\"\"Extract syntactic features using POS tagging\"\"\"\n",
    "        words = nltk.word_tokenize(text)\n",
    "        if not words:\n",
    "            return {f'{pos}_ratio': 0 for pos in ['noun', 'verb', 'adj', 'adv', 'prep', 'det']}\n",
    "        \n",
    "        pos_tags = nltk.pos_tag(words)\n",
    "        pos_counts = Counter([tag for word, tag in pos_tags])\n",
    "        total_tags = len(pos_tags)\n",
    "        \n",
    "        # Group POS tags into major categories\n",
    "        noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "        verb_tags = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "        adj_tags = ['JJ', 'JJR', 'JJS']\n",
    "        adv_tags = ['RB', 'RBR', 'RBS']\n",
    "        prep_tags = ['IN', 'TO']\n",
    "        det_tags = ['DT', 'PDT', 'WDT']\n",
    "        \n",
    "        features = {\n",
    "            'noun_ratio': sum(pos_counts[tag] for tag in noun_tags) / total_tags,\n",
    "            'verb_ratio': sum(pos_counts[tag] for tag in verb_tags) / total_tags,\n",
    "            'adj_ratio': sum(pos_counts[tag] for tag in adj_tags) / total_tags,\n",
    "            'adv_ratio': sum(pos_counts[tag] for tag in adv_tags) / total_tags,\n",
    "            'prep_ratio': sum(pos_counts[tag] for tag in prep_tags) / total_tags,\n",
    "            'det_ratio': sum(pos_counts[tag] for tag in det_tags) / total_tags\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _punctuation_features(self, text):\n",
    "        \"\"\"Extract punctuation usage features\"\"\"\n",
    "        total_chars = len(text)\n",
    "        if total_chars == 0:\n",
    "            return {f'{p}_ratio': 0 for p in ['comma', 'semicolon', 'colon', 'exclamation', 'question', 'period', 'quote']}\n",
    "        \n",
    "        features = {\n",
    "            'comma_ratio': text.count(',') / total_chars,\n",
    "            'semicolon_ratio': text.count(';') / total_chars,\n",
    "            'colon_ratio': text.count(':') / total_chars,\n",
    "            'exclamation_ratio': text.count('!') / total_chars,\n",
    "            'question_ratio': text.count('?') / total_chars,\n",
    "            'period_ratio': text.count('.') / total_chars,\n",
    "            'quote_ratio': (text.count('\"') + text.count(\"'\")) / total_chars\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _readability_features(self, text):\n",
    "        \"\"\"Extract readability features\"\"\"\n",
    "        try:\n",
    "            flesch_ease = flesch_reading_ease(text)\n",
    "            flesch_grade = flesch_kincaid_grade(text)\n",
    "        except:\n",
    "            flesch_ease = 0\n",
    "            flesch_grade = 0\n",
    "        \n",
    "        features = {\n",
    "            'flesch_reading_ease': flesch_ease,\n",
    "            'flesch_kincaid_grade': flesch_grade\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "\n",
    "# Extract stylometric features\n",
    "print(\"Extracting stylometric features...\")\n",
    "feature_extractor = StylometricFeatureExtractor()\n",
    "\n",
    "# Extract features for a sample of sentences\n",
    "sample_df = sentence_dataset.head(100).copy()\n",
    "features_list = []\n",
    "\n",
    "for idx, row in sample_df.iterrows():\n",
    "    features = feature_extractor.extract_features(row['text'])\n",
    "    features['author'] = row['author']\n",
    "    features['author_name'] = row['author_name']\n",
    "    features_list.append(features)\n",
    "\n",
    "features_df = pd.DataFrame(features_list)\n",
    "print(f\"Extracted {len(features_df.columns)-2} stylometric features\")\n",
    "print(\"\\nFeature columns:\", list(features_df.columns[:-2]))\n",
    "\n",
    "# Display feature statistics by author\n",
    "print(\"\\nStylometric Feature Analysis:\")\n",
    "feature_cols = [col for col in features_df.columns if col not in ['author', 'author_name']]\n",
    "author_features = features_df.groupby('author_name')[feature_cols].mean()\n",
    "print(author_features.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Vectorization Approaches\n",
    "\n",
    "We'll implement different text vectorization methods to convert text into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_features(texts, max_features=5000, ngram_range=(1, 2)):\n",
    "    \"\"\"Create TF-IDF features\"\"\"\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        ngram_range=ngram_range,\n",
    "        stop_words='english',\n",
    "        lowercase=True,\n",
    "        strip_accents='ascii'\n",
    "    )\n",
    "    \n",
    "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    return tfidf_matrix, vectorizer, feature_names\n",
    "\n",
    "def create_count_features(texts, max_features=5000, ngram_range=(1, 2)):\n",
    "    \"\"\"Create Count Vectorizer features\"\"\"\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=max_features,\n",
    "        ngram_range=ngram_range,\n",
    "        stop_words='english',\n",
    "        lowercase=True,\n",
    "        strip_accents='ascii'\n",
    "    )\n",
    "    \n",
    "    count_matrix = vectorizer.fit_transform(texts)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    \n",
    "    return count_matrix, vectorizer, feature_names\n",
    "\n",
    "def analyze_most_distinctive_features(tfidf_matrix, feature_names, labels, top_k=10):\n",
    "    \"\"\"Find most distinctive features for each author\"\"\"\n",
    "    authors = np.unique(labels)\n",
    "    \n",
    "    print(\"Most Distinctive Features by Author:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for author in authors:\n",
    "        # Get average TF-IDF scores for this author\n",
    "        author_mask = (labels == author)\n",
    "        author_tfidf = tfidf_matrix[author_mask].mean(axis=0).A1\n",
    "        \n",
    "        # Get average TF-IDF scores for other authors\n",
    "        other_mask = ~author_mask\n",
    "        other_tfidf = tfidf_matrix[other_mask].mean(axis=0).A1\n",
    "        \n",
    "        # Calculate distinctiveness (difference)\n",
    "        distinctiveness = author_tfidf - other_tfidf\n",
    "        \n",
    "        # Get top distinctive features\n",
    "        top_indices = np.argsort(distinctiveness)[-top_k:]\n",
    "        top_features = [(feature_names[i], distinctiveness[i]) for i in reversed(top_indices)]\n",
    "        \n",
    "        print(f\"\\n{author}:\")\n",
    "        for feature, score in top_features:\n",
    "            print(f\"  {feature}: {score:.4f}\")\n",
    "\n",
    "# Prepare data\n",
    "X_text = sentence_dataset['text'].values\n",
    "y = sentence_dataset['author'].values\n",
    "author_names = sentence_dataset['author_name'].values\n",
    "\n",
    "print(f\"Dataset size: {len(X_text)} samples\")\n",
    "print(f\"Authors: {np.unique(author_names)}\")\n",
    "\n",
    "# Create different vectorizations\n",
    "print(\"\\nCreating TF-IDF features...\")\n",
    "X_tfidf, tfidf_vectorizer, tfidf_features = create_tfidf_features(X_text, max_features=3000)\n",
    "print(f\"TF-IDF matrix shape: {X_tfidf.shape}\")\n",
    "\n",
    "print(\"\\nCreating Count features...\")\n",
    "X_count, count_vectorizer, count_features = create_count_features(X_text, max_features=3000)\n",
    "print(f\"Count matrix shape: {X_count.shape}\")\n",
    "\n",
    "# Analyze distinctive features\n",
    "analyze_most_distinctive_features(X_tfidf, tfidf_features, author_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Author Classification Models\n",
    "\n",
    "Let's build and compare different classification models for author identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
    "    \"\"\"Train and evaluate a classification model\"\"\"\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    return model, accuracy, y_pred\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, title):\n",
    "    \"\"\"Plot confusion matrix\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=labels, yticklabels=labels)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'Naive Bayes': MultinomialNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    trained_model, accuracy, predictions = evaluate_model(\n",
    "        model, X_train, X_test, y_train, y_test, name\n",
    "    )\n",
    "    results[name] = {\n",
    "        'model': trained_model,\n",
    "        'accuracy': accuracy,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "# Compare results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: {result['accuracy']:.4f}\")\n",
    "\n",
    "# Plot confusion matrix for best model\n",
    "best_model_name = max(results.keys(), key=lambda k: results[k]['accuracy'])\n",
    "best_predictions = results[best_model_name]['predictions']\n",
    "\n",
    "unique_authors = np.unique(y)\n",
    "plot_confusion_matrix(y_test, best_predictions, unique_authors, \n",
    "                     f'Confusion Matrix - {best_model_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_feature_importance(model, feature_names, top_k=20):\n",
    "    \"\"\"Analyze feature importance for the model\"\"\"\n",
    "    if hasattr(model, 'coef_'):\n",
    "        # For linear models (Logistic Regression, SVM)\n",
    "        if len(model.coef_.shape) > 1:  # Multi-class\n",
    "            # Average absolute coefficients across classes\n",
    "            importance = np.mean(np.abs(model.coef_), axis=0)\n",
    "        else:\n",
    "            importance = np.abs(model.coef_[0])\n",
    "    elif hasattr(model, 'feature_importances_'):\n",
    "        # For tree-based models (Random Forest)\n",
    "        importance = model.feature_importances_\n",
    "    else:\n",
    "        print(\"Feature importance not available for this model type\")\n",
    "        return\n",
    "    \n",
    "    # Get top features\n",
    "    top_indices = np.argsort(importance)[-top_k:]\n",
    "    top_features = [(feature_names[i], importance[i]) for i in reversed(top_indices)]\n",
    "    \n",
    "    print(f\"Top {top_k} Most Important Features:\")\n",
    "    print(\"-\" * 40)\n",
    "    for i, (feature, score) in enumerate(top_features, 1):\n",
    "        print(f\"{i:2d}. {feature}: {score:.4f}\")\n",
    "    \n",
    "    # Plot feature importance\n",
    "    features, scores = zip(*top_features)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    y_pos = np.arange(len(features))\n",
    "    plt.barh(y_pos, scores)\n",
    "    plt.yticks(y_pos, features)\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title('Top Features by Importance')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze feature importance for best model\n",
    "best_model = results[best_model_name]['model']\n",
    "print(f\"Feature importance analysis for {best_model_name}:\")\n",
    "analyze_feature_importance(best_model, tfidf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Cross-Validation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_grid_search(X, y, model_params, cv=5):\n",
    "    \"\"\"Perform grid search for hyperparameter tuning\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_name, (model, param_grid) in model_params.items():\n",
    "        print(f\"\\nTuning {model_name}...\")\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            model, param_grid, cv=cv, scoring='accuracy', n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        results[model_name] = {\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_model': grid_search.best_estimator_\n",
    "        }\n",
    "        \n",
    "        print(f\"Best score: {grid_search.best_score_:.4f}\")\n",
    "        print(f\"Best params: {grid_search.best_params_}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Define parameter grids for tuning\n",
    "param_grids = {\n",
    "    'Logistic Regression': (LogisticRegression(random_state=42, max_iter=1000), {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['liblinear', 'lbfgs']\n",
    "    }),\n",
    "    'Random Forest': (RandomForestClassifier(random_state=42), {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5]\n",
    "    }),\n",
    "    'SVM': (SVC(random_state=42), {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    })\n",
    "}\n",
    "\n",
    "# Perform grid search on a subset for speed\n",
    "X_subset = X_tfidf[:1000]  # Use subset for faster tuning\n",
    "y_subset = y[:1000]\n",
    "\n",
    "print(\"Performing hyperparameter tuning...\")\n",
    "tuning_results = perform_grid_search(X_subset, y_subset, param_grids)\n",
    "\n",
    "# Compare tuned vs default models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TUNED MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "for name, result in tuning_results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  Best CV Score: {result['best_score']:.4f}\")\n",
    "    print(f\"  Best Parameters: {result['best_params']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Interpretation and Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_author_with_confidence(text, model, vectorizer, label_encoder=None):\n",
    "    \"\"\"Predict author with confidence scores\"\"\"\n",
    "    # Vectorize text\n",
    "    text_vector = vectorizer.transform([text])\n",
    "    \n",
    "    # Get prediction\n",
    "    prediction = model.predict(text_vector)[0]\n",
    "    \n",
    "    # Get confidence scores if available\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        probabilities = model.predict_proba(text_vector)[0]\n",
    "        classes = model.classes_\n",
    "        \n",
    "        # Create confidence dict\n",
    "        confidence = {classes[i]: prob for i, prob in enumerate(probabilities)}\n",
    "    else:\n",
    "        confidence = {prediction: 1.0}\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "def demonstrate_predictions():\n",
    "    \"\"\"Demonstrate model predictions on sample texts\"\"\"\n",
    "    # Get best model\n",
    "    best_model = results[best_model_name]['model']\n",
    "    \n",
    "    # Sample texts from test set\n",
    "    test_indices = np.random.choice(range(len(X_test)), 5, replace=False)\n",
    "    \n",
    "    print(\"Sample Predictions:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, idx in enumerate(test_indices):\n",
    "        # Get original text\n",
    "        original_idx = X_test.indices[idx] if hasattr(X_test, 'indices') else idx\n",
    "        text = X_text[original_idx] if original_idx < len(X_text) else \"Sample text not available\"\n",
    "        true_author = y_test[idx]\n",
    "        \n",
    "        # Make prediction\n",
    "        pred_author, confidence = predict_author_with_confidence(\n",
    "            text, best_model, tfidf_vectorizer\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Text: {text[:200]}...\" if len(text) > 200 else f\"Text: {text}\")\n",
    "        print(f\"True Author: {true_author}\")\n",
    "        print(f\"Predicted Author: {pred_author}\")\n",
    "        print(f\"Correct: {'✓' if pred_author == true_author else '✗'}\")\n",
    "        \n",
    "        # Show confidence scores\n",
    "        print(\"Confidence scores:\")\n",
    "        for author, score in sorted(confidence.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {author}: {score:.3f}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "demonstrate_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Challenge Section\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Advanced Stylometric Features\n",
    "\n",
    "Implement additional sophisticated stylometric features that could improve author identification.\n",
    "\n",
    "**Tasks:**\n",
    "1. Implement dependency parsing features (using spaCy)\n",
    "2. Add word complexity measures (syllable count, rare word usage)\n",
    "3. Extract rhythm and cadence features (stress patterns)\n",
    "4. Implement semantic coherence measures\n",
    "5. Compare performance with baseline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement advanced stylometric features\n",
    "class AdvancedStylometricExtractor:\n",
    "    def __init__(self):\n",
    "        # Initialize any required resources (e.g., spaCy model)\n",
    "        pass\n",
    "    \n",
    "    def extract_dependency_features(self, text):\n",
    "        \"\"\"\n",
    "        Extract features based on dependency parsing\n",
    "        - Average dependency tree depth\n",
    "        - Frequency of different dependency relations\n",
    "        - Sentence complexity measures\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def extract_complexity_features(self, text):\n",
    "        \"\"\"\n",
    "        Extract word and sentence complexity features\n",
    "        - Average syllable count per word\n",
    "        - Frequency of rare/complex words\n",
    "        - Lexical sophistication measures\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def extract_rhythm_features(self, text):\n",
    "        \"\"\"\n",
    "        Extract rhythm and cadence features\n",
    "        - Stress pattern analysis\n",
    "        - Syllable rhythm patterns\n",
    "        - Sentence rhythm variability\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def extract_semantic_features(self, text):\n",
    "        \"\"\"\n",
    "        Extract semantic coherence and topic features\n",
    "        - Topic consistency measures\n",
    "        - Semantic similarity between sentences\n",
    "        - Abstract vs concrete word usage\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "# TODO: Compare advanced features with baseline\n",
    "# Your implementation and evaluation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Deep Learning Approach\n",
    "\n",
    "Implement a neural network-based approach for authorship attribution.\n",
    "\n",
    "**Tasks:**\n",
    "1. Build a CNN-based model for character-level analysis\n",
    "2. Implement an LSTM model for sequence-level features\n",
    "3. Create a Transformer-based model using pre-trained embeddings\n",
    "4. Compare deep learning approaches with traditional ML methods\n",
    "5. Analyze what the neural networks learn about writing style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement deep learning models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class CharacterCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes):\n",
    "        super(CharacterCNN, self).__init__()\n",
    "        # TODO: Implement CNN for character-level analysis\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "\n",
    "class AuthorLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_classes):\n",
    "        super(AuthorLSTM, self).__init__()\n",
    "        # TODO: Implement LSTM for sequence analysis\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, pretrained_model_name, num_classes):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        # TODO: Implement transformer-based classifier\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        pass\n",
    "\n",
    "# TODO: Training and evaluation functions\n",
    "def train_deep_model(model, train_loader, val_loader, epochs=10):\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def evaluate_deep_model(model, test_loader):\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: Cross-Domain Author Attribution\n",
    "\n",
    "Test the robustness of your models across different text domains and time periods.\n",
    "\n",
    "**Tasks:**\n",
    "1. Collect texts from different genres (fiction, non-fiction, poetry, journalism)\n",
    "2. Analyze how writing style changes over time periods\n",
    "3. Build domain-adaptive models\n",
    "4. Evaluate cross-domain generalization\n",
    "5. Implement domain adaptation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement cross-domain analysis\n",
    "def collect_multi_domain_texts():\n",
    "    \"\"\"\n",
    "    Collect texts from different domains:\n",
    "    - Fiction vs Non-fiction\n",
    "    - Different time periods\n",
    "    - Different genres\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def analyze_domain_shift(source_domain_data, target_domain_data):\n",
    "    \"\"\"\n",
    "    Analyze how stylometric features change across domains\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def build_domain_adaptive_model(source_data, target_data):\n",
    "    \"\"\"\n",
    "    Build models that can adapt across domains\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# TODO: Evaluate cross-domain performance\n",
    "def evaluate_cross_domain_performance(models, datasets):\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Authorship Verification vs Attribution\n",
    "\n",
    "Implement authorship verification (binary: same author or not) in addition to attribution (multi-class).\n",
    "\n",
    "**Tasks:**\n",
    "1. Reformulate the problem as verification (1-vs-all)\n",
    "2. Implement Siamese networks for similarity learning\n",
    "3. Use distance-based methods for verification\n",
    "4. Compare verification vs attribution performance\n",
    "5. Implement few-shot learning for new authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement authorship verification\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        # TODO: Implement Siamese network for similarity learning\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        # TODO: Implement forward pass for pair of texts\n",
    "        pass\n",
    "\n",
    "def create_verification_dataset(attribution_data):\n",
    "    \"\"\"\n",
    "    Create pairs of texts with same/different author labels\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def distance_based_verification(text1, text2, model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Verify if two texts are by the same author using distance metrics\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def few_shot_author_learning(support_texts, query_text, k=5):\n",
    "    \"\"\"\n",
    "    Learn to identify a new author from few examples\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 5: Adversarial Authorship\n",
    "\n",
    "Explore how authors might try to disguise their writing style and how to make models robust to such attempts.\n",
    "\n",
    "**Tasks:**\n",
    "1. Simulate style transfer attacks (making text look like another author)\n",
    "2. Implement adversarial training for robustness\n",
    "3. Analyze which features are most vulnerable to manipulation\n",
    "4. Develop detection methods for style mimicry\n",
    "5. Build robust features that resist manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement adversarial authorship analysis\n",
    "def simulate_style_transfer(source_text, target_author_style):\n",
    "    \"\"\"\n",
    "    Simulate attempts to disguise writing style\n",
    "    - Vocabulary substitution\n",
    "    - Sentence structure changes\n",
    "    - Punctuation modification\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def adversarial_training(model, training_data, attack_function):\n",
    "    \"\"\"\n",
    "    Train model to be robust against style manipulation\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def analyze_feature_vulnerability(features, attack_methods):\n",
    "    \"\"\"\n",
    "    Analyze which stylometric features are most vulnerable\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "def detect_style_mimicry(text, suspected_true_author, claimed_author):\n",
    "    \"\"\"\n",
    "    Detect if text has been artificially modified to mimic another style\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 6: Real-World Application\n",
    "\n",
    "Build a practical authorship attribution system for a specific use case.\n",
    "\n",
    "**Tasks:**\n",
    "1. Choose a specific application (plagiarism detection, forensics, etc.)\n",
    "2. Collect appropriate real-world data\n",
    "3. Handle practical challenges (short texts, noisy data, unknown authors)\n",
    "4. Build an end-to-end system with user interface\n",
    "5. Evaluate on realistic scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement real-world application\n",
    "class AuthorshipAttributionSystem:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.vectorizers = {}\n",
    "        self.author_profiles = {}\n",
    "    \n",
    "    def train_system(self, training_data):\n",
    "        \"\"\"\n",
    "        Train the complete authorship attribution system\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def predict_author(self, text, return_confidence=True):\n",
    "        \"\"\"\n",
    "        Predict the author of a given text\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def handle_unknown_author(self, text):\n",
    "        \"\"\"\n",
    "        Detect when text is from an unknown author\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def handle_short_text(self, text):\n",
    "        \"\"\"\n",
    "        Handle attribution for very short texts\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def update_author_profile(self, author, new_texts):\n",
    "        \"\"\"\n",
    "        Update author profile with new writing samples\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "# TODO: Build user interface\n",
    "def create_web_interface():\n",
    "    \"\"\"\n",
    "    Create a web interface for the authorship attribution system\n",
    "    \"\"\"\n",
    "    # You can use Gradio or Streamlit for this\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 7: Analysis Questions\n",
    "\n",
    "Answer these questions based on your experiments:\n",
    "\n",
    "1. **Feature Effectiveness**: Which types of stylometric features are most effective for author identification? Why?\n",
    "\n",
    "2. **Text Length Impact**: How does the length of text samples affect attribution accuracy? What's the minimum viable length?\n",
    "\n",
    "3. **Genre Effects**: How does writing genre affect the effectiveness of different features?\n",
    "\n",
    "4. **Temporal Stability**: How stable are writing styles over time? What challenges does this pose?\n",
    "\n",
    "5. **Privacy Implications**: What are the privacy and ethical implications of authorship attribution technology?\n",
    "\n",
    "6. **Robustness**: How can we make authorship attribution systems more robust to deliberate deception?\n",
    "\n",
    "7. **Future Directions**: What are the most promising research directions in computational stylometry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answers:\n",
    "\n",
    "**1. Feature Effectiveness:**\n",
    "<!-- Your analysis here -->\n",
    "\n",
    "**2. Text Length Impact:**\n",
    "<!-- Your analysis here -->\n",
    "\n",
    "**3. Genre Effects:**\n",
    "<!-- Your analysis here -->\n",
    "\n",
    "**4. Temporal Stability:**\n",
    "<!-- Your analysis here -->\n",
    "\n",
    "**5. Privacy Implications:**\n",
    "<!-- Your analysis here -->\n",
    "\n",
    "**6. Robustness:**\n",
    "<!-- Your analysis here -->\n",
    "\n",
    "**7. Future Directions:**\n",
    "<!-- Your analysis here -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge: Multi-Modal Authorship Attribution\n",
    "\n",
    "Extend beyond text to include other modalities that might reveal authorship.\n",
    "\n",
    "**Tasks:**\n",
    "1. Analyze typing patterns and timing (if available)\n",
    "2. Include metadata features (posting times, frequency patterns)\n",
    "3. Combine textual and behavioral features\n",
    "4. Explore cross-modal consistency in authorship\n",
    "5. Build multi-modal fusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement multi-modal authorship attribution\n",
    "class MultiModalAuthorshipModel:\n",
    "    def __init__(self):\n",
    "        self.text_model = None\n",
    "        self.behavioral_model = None\n",
    "        self.fusion_model = None\n",
    "    \n",
    "    def extract_behavioral_features(self, metadata):\n",
    "        \"\"\"\n",
    "        Extract behavioral features from metadata:\n",
    "        - Posting time patterns\n",
    "        - Writing frequency\n",
    "        - Response time patterns\n",
    "        - Activity patterns\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def extract_typing_features(self, keystroke_data):\n",
    "        \"\"\"\n",
    "        Extract typing pattern features:\n",
    "        - Dwell time (key press duration)\n",
    "        - Flight time (between key presses)\n",
    "        - Typing rhythm patterns\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def fuse_modalities(self, text_features, behavioral_features, typing_features):\n",
    "        \"\"\"\n",
    "        Combine features from different modalities\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}