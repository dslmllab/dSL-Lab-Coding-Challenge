{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing Fundamentals for NLP\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Master text cleaning techniques** for real-world data\n",
    "2. **Implement tokenization strategies** for different languages\n",
    "3. **Apply normalization methods** including stemming and lemmatization\n",
    "4. **Handle special text formats** (emails, URLs, social media)\n",
    "5. **Build robust preprocessing pipelines** for various NLP tasks\n",
    "6. **Understand encoding and unicode issues** in text processing\n",
    "7. **Create custom preprocessing functions** for domain-specific text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Text preprocessing is the foundation of any successful NLP project. Raw text data is often messy, inconsistent, and contains various artifacts that can hinder model performance. This notebook covers comprehensive text preprocessing techniques from basic to advanced.\n",
    "\n",
    "### Why Preprocessing Matters:\n",
    "- **Noise Reduction**: Remove irrelevant characters and formatting\n",
    "- **Standardization**: Ensure consistent text format\n",
    "- **Feature Engineering**: Transform text into meaningful features\n",
    "- **Performance**: Improve model accuracy and training efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T14:53:29.662629Z",
     "start_time": "2025-07-02T14:53:02.482174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.24.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (3.7.3)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.13.2)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 9.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting spacy\n",
      "  Downloading spacy-3.8.2.tar.gz (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 35.9 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-jdn0q4uj/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'murmurhash>=0.28.0,<1.1.0' 'thinc>=8.3.0,<8.4.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"''\n",
      "       cwd: None\n",
      "  Complete output (268 lines):\n",
      "  Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "  Collecting cython<3.0,>=0.25\n",
      "    Downloading Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Downloading preshed-3.0.10.tar.gz (15 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "      Preparing wheel metadata: started\n",
      "      Preparing wheel metadata: finished with status 'done'\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "  Collecting thinc<8.4.0,>=8.3.0\n",
      "    Downloading thinc-8.3.2.tar.gz (193 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'error'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-lcub172x/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'murmurhash>=1.0.2,<1.1.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'blis>=1.0.0,<1.1.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"''\n",
      "         cwd: None\n",
      "    Complete output (73 lines):\n",
      "    Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "    Collecting setuptools\n",
      "      Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "    Collecting cython<3.0,>=0.25\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "    Collecting murmurhash<1.1.0,>=1.0.2\n",
      "      Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "    Collecting cymem<2.1.0,>=2.0.2\n",
      "      Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "    Collecting preshed<3.1.0,>=3.0.2\n",
      "      Using cached preshed-3.0.10.tar.gz (15 kB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing wheel metadata: started\n",
      "        Preparing wheel metadata: finished with status 'done'\n",
      "    Collecting blis<1.1.0,>=1.0.0\n",
      "      Downloading blis-1.0.2.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-43k3pqxo/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/8a/69/8686634ff12188a7ac5dad16472cc66f166f6d4c34babfe8bcb4ef44ab7c/blis-1.0.2.tar.gz#sha256=68df878871a9db34efd58f648e12e06806e381991bd9e70df198c33d7b259383 (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-43k3pqxo/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "      Downloading blis-1.0.1.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-pg9cv_9k/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/bd/e4/741f20c9b767330e2605d4c71a775303cb6a9c72764b8802232fe6c7afad/blis-1.0.1.tar.gz#sha256=91739cd850ca8100dcddbd8ad66942cab20c9473cdea9a35b165b11d7b8d91e4 (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-pg9cv_9k/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "      Downloading blis-1.0.0.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-vwizefa4/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/b6/0b/a73be025d991e8795626a830314984f7bda5de440e80b72a53bc316bb870/blis-1.0.0.tar.gz#sha256=9ea14649ff07457e4112c7b94605e4aeb4f2fd5a8bd57c296ff8fbd154966ede (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-vwizefa4/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "    ERROR: Could not find a version that satisfies the requirement blis<1.1.0,>=1.0.0 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.8, 0.0.9.dev104, 0.0.10, 0.0.12, 0.0.13, 0.0.16, 0.1.0, 0.2.0.dev0, 0.2.0, 0.2.1, 0.2.2.dev0, 0.2.2, 0.2.3.dev0, 0.2.3.dev1, 0.2.3.dev2, 0.2.3.dev3, 0.2.3, 0.2.4, 0.3.1, 0.4.0.dev0, 0.4.0.dev1, 0.4.0, 0.4.1, 0.7.0, 0.7.1.dev0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.9.0, 0.9.1.dev0, 0.9.1.dev1, 0.9.1, 1.0.0a1, 1.0.0, 1.0.1, 1.0.2, 1.2.0, 1.2.1, 1.3.0)\n",
      "    ERROR: No matching distribution found for blis<1.1.0,>=1.0.0\n",
      "    WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "    You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "    ----------------------------------------\n",
      "  WARNING: Discarding https://files.pythonhosted.org/packages/8a/9f/b2193b69dd112a46800182e897cda2fc9c497dfdd9352a0c5ba9252cf5f0/thinc-8.3.2.tar.gz#sha256=3e8ef69eac89a601e11d47fc9e43d26ffe7ef682dcf667c94ff35ff690549aeb (from https://pypi.org/simple/thinc/) (requires-python:>=3.6). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-lcub172x/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'murmurhash>=1.0.2,<1.1.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'blis>=1.0.0,<1.1.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"'' Check the logs for full command output.\n",
      "    Downloading thinc-8.3.1.tar.gz (193 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'error'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-sv8vcpn8/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'murmurhash>=1.0.2,<1.1.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'blis>=1.0.0,<1.1.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"''\n",
      "         cwd: None\n",
      "    Complete output (73 lines):\n",
      "    Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "    Collecting setuptools\n",
      "      Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "    Collecting cython<3.0,>=0.25\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "    Collecting murmurhash<1.1.0,>=1.0.2\n",
      "      Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "    Collecting cymem<2.1.0,>=2.0.2\n",
      "      Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "    Collecting preshed<3.1.0,>=3.0.2\n",
      "      Using cached preshed-3.0.10.tar.gz (15 kB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing wheel metadata: started\n",
      "        Preparing wheel metadata: finished with status 'done'\n",
      "    Collecting blis<1.1.0,>=1.0.0\n",
      "      Using cached blis-1.0.2.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-pxk4lmue/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/8a/69/8686634ff12188a7ac5dad16472cc66f166f6d4c34babfe8bcb4ef44ab7c/blis-1.0.2.tar.gz#sha256=68df878871a9db34efd58f648e12e06806e381991bd9e70df198c33d7b259383 (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-pxk4lmue/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "      Using cached blis-1.0.1.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-5k9sjawa/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/bd/e4/741f20c9b767330e2605d4c71a775303cb6a9c72764b8802232fe6c7afad/blis-1.0.1.tar.gz#sha256=91739cd850ca8100dcddbd8ad66942cab20c9473cdea9a35b165b11d7b8d91e4 (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-5k9sjawa/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "      Using cached blis-1.0.0.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-y0tujonf/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/b6/0b/a73be025d991e8795626a830314984f7bda5de440e80b72a53bc316bb870/blis-1.0.0.tar.gz#sha256=9ea14649ff07457e4112c7b94605e4aeb4f2fd5a8bd57c296ff8fbd154966ede (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-y0tujonf/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "    ERROR: Could not find a version that satisfies the requirement blis<1.1.0,>=1.0.0 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.8, 0.0.9.dev104, 0.0.10, 0.0.12, 0.0.13, 0.0.16, 0.1.0, 0.2.0.dev0, 0.2.0, 0.2.1, 0.2.2.dev0, 0.2.2, 0.2.3.dev0, 0.2.3.dev1, 0.2.3.dev2, 0.2.3.dev3, 0.2.3, 0.2.4, 0.3.1, 0.4.0.dev0, 0.4.0.dev1, 0.4.0, 0.4.1, 0.7.0, 0.7.1.dev0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.9.0, 0.9.1.dev0, 0.9.1.dev1, 0.9.1, 1.0.0a1, 1.0.0, 1.0.1, 1.0.2, 1.2.0, 1.2.1, 1.3.0)\n",
      "    ERROR: No matching distribution found for blis<1.1.0,>=1.0.0\n",
      "    WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "    You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "    ----------------------------------------\n",
      "  WARNING: Discarding https://files.pythonhosted.org/packages/ea/60/b7d645d621a47d649975b53c13cdf3e66b456a24727ccd34794f1014f45c/thinc-8.3.1.tar.gz#sha256=44e747bbf93e981dfded7d432b68ef1ba75b28ef46fc51f185477970743b36e9 (from https://pypi.org/simple/thinc/) (requires-python:>=3.6). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-sv8vcpn8/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'murmurhash>=1.0.2,<1.1.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'blis>=1.0.0,<1.1.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"'' Check the logs for full command output.\n",
      "    Downloading thinc-8.3.0.tar.gz (193 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'error'\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-6w1f2t4f/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'murmurhash>=1.0.2,<1.1.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'blis>=1.0.0,<1.1.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"''\n",
      "         cwd: None\n",
      "    Complete output (73 lines):\n",
      "    Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "    Collecting setuptools\n",
      "      Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "    Collecting cython<3.0,>=0.25\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "    Collecting murmurhash<1.1.0,>=1.0.2\n",
      "      Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "    Collecting cymem<2.1.0,>=2.0.2\n",
      "      Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "    Collecting preshed<3.1.0,>=3.0.2\n",
      "      Using cached preshed-3.0.10.tar.gz (15 kB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "        Preparing wheel metadata: started\n",
      "        Preparing wheel metadata: finished with status 'done'\n",
      "    Collecting blis<1.1.0,>=1.0.0\n",
      "      Using cached blis-1.0.2.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-h09wrp9a/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/8a/69/8686634ff12188a7ac5dad16472cc66f166f6d4c34babfe8bcb4ef44ab7c/blis-1.0.2.tar.gz#sha256=68df878871a9db34efd58f648e12e06806e381991bd9e70df198c33d7b259383 (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-h09wrp9a/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "      Using cached blis-1.0.1.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-cwk6njzj/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/bd/e4/741f20c9b767330e2605d4c71a775303cb6a9c72764b8802232fe6c7afad/blis-1.0.1.tar.gz#sha256=91739cd850ca8100dcddbd8ad66942cab20c9473cdea9a35b165b11d7b8d91e4 (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-cwk6njzj/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "      Using cached blis-1.0.0.tar.gz (3.6 MB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      ERROR: Command errored out with exit status 1:\n",
      "       command: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-vmz2brfp/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0'\n",
      "           cwd: None\n",
      "      Complete output (8 lines):\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-75.3.2-py3-none-any.whl (1.3 MB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl (3.1 MB)\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "      You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "      ----------------------------------------\n",
      "    WARNING: Discarding https://files.pythonhosted.org/packages/b6/0b/a73be025d991e8795626a830314984f7bda5de440e80b72a53bc316bb870/blis-1.0.0.tar.gz#sha256=9ea14649ff07457e4112c7b94605e4aeb4f2fd5a8bd57c296ff8fbd154966ede (from https://pypi.org/simple/blis/). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-vmz2brfp/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25' 'numpy>=2.0.0,<3.0.0' Check the logs for full command output.\n",
      "    ERROR: Could not find a version that satisfies the requirement blis<1.1.0,>=1.0.0 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.8, 0.0.9.dev104, 0.0.10, 0.0.12, 0.0.13, 0.0.16, 0.1.0, 0.2.0.dev0, 0.2.0, 0.2.1, 0.2.2.dev0, 0.2.2, 0.2.3.dev0, 0.2.3.dev1, 0.2.3.dev2, 0.2.3.dev3, 0.2.3, 0.2.4, 0.3.1, 0.4.0.dev0, 0.4.0.dev1, 0.4.0, 0.4.1, 0.7.0, 0.7.1.dev0, 0.7.1, 0.7.2, 0.7.3, 0.7.4, 0.7.5, 0.7.6, 0.7.7, 0.7.8, 0.7.9, 0.7.10, 0.7.11, 0.9.0, 0.9.1.dev0, 0.9.1.dev1, 0.9.1, 1.0.0a1, 1.0.0, 1.0.1, 1.0.2, 1.2.0, 1.2.1, 1.3.0)\n",
      "    ERROR: No matching distribution found for blis<1.1.0,>=1.0.0\n",
      "    WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "    You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "    ----------------------------------------\n",
      "  WARNING: Discarding https://files.pythonhosted.org/packages/15/0a/250f7fa34632616bb4fc37decbc46ed09243bade708968dc869d8a4c144b/thinc-8.3.0.tar.gz#sha256=eb3bed54f5c00ec9addaaa208c51ccfa059483d73140cd515aa33373715c6e59 (from https://pypi.org/simple/thinc/) (requires-python:>=3.6). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-6w1f2t4f/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'murmurhash>=1.0.2,<1.1.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'blis>=1.0.0,<1.1.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"'' Check the logs for full command output.\n",
      "  ERROR: Could not find a version that satisfies the requirement thinc<8.4.0,>=8.3.0 (from versions: 1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.41, 1.42, 1.60, 1.61, 1.62, 1.63, 1.64, 1.65, 1.66, 1.67, 1.68, 1.69, 1.70, 1.71, 1.72, 1.73, 1.74, 1.75, 1.76, 2.0, 3.0, 3.1, 3.2, 3.3, 3.4.1, 4.0.0, 4.1.0, 4.2.0, 5.0.0, 5.0.1, 5.0.2, 5.0.3, 5.0.4, 5.0.5, 5.0.6, 5.0.7, 5.0.8, 6.0.0, 6.1.0, 6.1.1, 6.1.2, 6.1.3, 6.2.0, 6.3.0, 6.4.0, 6.5.0, 6.5.2, 6.6.0, 6.7.0, 6.7.1, 6.7.2, 6.7.3, 6.8.0, 6.8.1, 6.8.2, 6.9.0, 6.10.0, 6.10.1.dev0, 6.10.1, 6.10.2.dev0, 6.10.2.dev1, 6.10.2, 6.10.3.dev0, 6.10.3.dev1, 6.10.3, 6.10.4.dev0, 6.11.0.dev2, 6.11.1.dev0, 6.11.1.dev1, 6.11.1.dev2, 6.11.1.dev3, 6.11.1.dev4, 6.11.1.dev6, 6.11.1.dev7, 6.11.1.dev10, 6.11.1.dev11, 6.11.1.dev12, 6.11.1.dev13, 6.11.1.dev15, 6.11.1.dev16, 6.11.1.dev17, 6.11.1.dev18, 6.11.1.dev19, 6.11.1.dev20, 6.11.1, 6.11.2.dev0, 6.11.2, 6.11.3.dev1, 6.11.3.dev2, 6.12.0, 6.12.1, 7.0.0.dev0, 7.0.0.dev1, 7.0.0.dev2, 7.0.0.dev3, 7.0.0.dev4, 7.0.0.dev5, 7.0.0.dev6, 7.0.0.dev8, 7.0.0, 7.0.1.dev0, 7.0.1.dev1, 7.0.1.dev2, 7.0.1, 7.0.2, 7.0.3, 7.0.4.dev0, 7.0.4, 7.0.5.dev0, 7.0.5, 7.0.6, 7.0.7, 7.0.8, 7.1.0.dev0, 7.1.0, 7.1.1, 7.2.0.dev3, 7.2.0, 7.3.0.dev0, 7.3.0, 7.3.1, 7.4.0.dev0, 7.4.0.dev1, 7.4.0.dev2, 7.4.0, 7.4.1, 7.4.2, 7.4.3, 7.4.4, 7.4.5, 7.4.6, 8.0.0.dev0, 8.0.0.dev2, 8.0.0.dev4, 8.0.0a0, 8.0.0a1, 8.0.0a2, 8.0.0a3, 8.0.0a6, 8.0.0a8, 8.0.0a9, 8.0.0a11, 8.0.0a12, 8.0.0a13, 8.0.0a14, 8.0.0a16, 8.0.0a17, 8.0.0a18, 8.0.0a19, 8.0.0a20, 8.0.0a21, 8.0.0a22, 8.0.0a23, 8.0.0a24, 8.0.0a25, 8.0.0a26, 8.0.0a27, 8.0.0a28, 8.0.0a29, 8.0.0a30, 8.0.0a31, 8.0.0a32, 8.0.0a33, 8.0.0a34, 8.0.0a35, 8.0.0a36, 8.0.0a40, 8.0.0a41, 8.0.0a42, 8.0.0a43, 8.0.0a44, 8.0.0rc0, 8.0.0rc1, 8.0.0rc2, 8.0.0rc3, 8.0.0rc4, 8.0.0rc5, 8.0.0rc6.dev0, 8.0.0rc6, 8.0.0, 8.0.1, 8.0.2, 8.0.3, 8.0.4, 8.0.5, 8.0.6, 8.0.7, 8.0.8, 8.0.9, 8.0.10, 8.0.11, 8.0.12, 8.0.13, 8.0.14.dev0, 8.0.14, 8.0.15, 8.0.16, 8.0.17, 8.1.0.dev0, 8.1.0.dev1, 8.1.0.dev2, 8.1.0.dev3, 8.1.0, 8.1.1, 8.1.2, 8.1.3, 8.1.4, 8.1.5, 8.1.6, 8.1.7, 8.1.8, 8.1.9, 8.1.10, 8.1.11, 8.1.12, 8.2.0, 8.2.1, 8.2.2, 8.2.3, 8.2.4, 8.2.5, 8.3.0, 8.3.1, 8.3.2, 9.0.0.dev0, 9.0.0.dev1, 9.0.0.dev2, 9.0.0.dev3, 9.0.0.dev4, 9.0.0.dev5)\n",
      "  ERROR: No matching distribution found for thinc<8.4.0,>=8.3.0\n",
      "  WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "  You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/07/53/536941af8fbb5cb10a778f0dbd2a17b0f13e7ebfc11e67b154be60508fdf/spacy-3.8.2.tar.gz#sha256=4b37ebd25ada4059b0dc9e0893e70dde5df83485329a068ef04580e70892a65d (from https://pypi.org/simple/spacy/) (requires-python:>=3.7). Command errored out with exit status 1: /Library/Frameworks/Python.framework/Versions/3.8/bin/python3 /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-standalone-pip-qhsx1t82/__env_pip__.zip/pip install --ignore-installed --no-user --prefix /private/var/folders/7x/4b9tm2d111j5qqd94k87nqxw0000gn/T/pip-build-env-jdn0q4uj/overlay --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- setuptools 'cython>=0.25,<3.0' 'cymem>=2.0.2,<2.1.0' 'preshed>=3.0.2,<3.1.0' 'murmurhash>=0.28.0,<1.1.0' 'thinc>=8.3.0,<8.4.0' 'numpy>=2.0.0,<2.1.0; python_version < '\"'\"'3.9'\"'\"'' 'numpy>=2.0.0,<2.1.0; python_version >= '\"'\"'3.9'\"'\"'' Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading spacy-3.7.5-cp38-cp38-macosx_10_9_x86_64.whl (6.8 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |                                | 10 kB 24.9 MB/s eta 0:00:01\r",
      "\u001b[K     |                                | 20 kB 34.2 MB/s eta 0:00:01\r",
      "\u001b[K     |▏                               | 30 kB 46.4 MB/s eta 0:00:01\r",
      "\u001b[K     |▏                               | 40 kB 30.0 MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 51 kB 34.2 MB/s eta 0:00:01\r",
      "\u001b[K     |▎                               | 61 kB 39.4 MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 71 kB 43.6 MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 81 kB 48.3 MB/s eta 0:00:01\r",
      "\u001b[K     |▍                               | 92 kB 52.4 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 102 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▌                               | 112 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 122 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 133 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 143 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 153 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 163 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 174 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 184 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 194 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 204 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 215 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 225 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 235 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 245 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 256 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 266 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 276 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 286 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▍                              | 296 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 307 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 317 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 327 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 337 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 348 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 358 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 368 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 378 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 389 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 399 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 409 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 419 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 430 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 440 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 450 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 460 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 471 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 481 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 491 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 501 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 512 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 522 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 532 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 542 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 552 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 563 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 573 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▊                             | 583 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 593 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 604 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 614 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 624 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 634 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 645 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 655 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 665 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 675 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 686 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 696 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 706 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 716 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▍                            | 727 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 737 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 747 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 757 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 768 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 778 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 788 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▊                            | 798 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 808 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 819 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 829 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 839 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 849 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 860 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 870 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 880 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 890 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 901 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 911 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 921 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 931 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 942 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 952 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▌                           | 962 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 972 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 983 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 993 kB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 1.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 1.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 1.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 1.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 1.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▏                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 1.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▌                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 1.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 1.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 1.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 1.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▌                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▊                        | 1.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 1.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 1.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 1.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 2.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 2.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 2.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 2.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 2.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▉                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 2.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▏                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 2.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▌                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▉                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 2.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 2.8 MB 56.1 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |█████████████                   | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▏                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 2.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 2.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 3.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 3.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 3.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▌                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 3.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 3.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 3.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▏              | 3.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 3.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▉              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 3.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▍             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 3.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▊             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 4.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 4.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 4.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 4.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▊           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 4.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 4.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▉          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 4.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▏         | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 4.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 4.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 4.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▍        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 5.0 MB 56.1 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[K     |███████████████████████▊        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▊        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 5.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▏       | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 5.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▌       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 5.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 5.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 5.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 5.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▎     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 5.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▋     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 5.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 5.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 5.9 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 6.0 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 6.1 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 6.2 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 6.3 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 6.4 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 6.5 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████ | 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 6.6 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▋| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 6.7 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 6.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 6.8 MB 56.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 6.8 MB 56.1 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 6.8 MB 56.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (4.67.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (6.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from nltk) (2024.11.6)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 29.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.10.tar.gz (15 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (2.32.3)\n",
      "Collecting typer<1.0.0,>=0.3.0\n",
      "  Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (58.0.4)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from spacy) (3.1.5)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.8-cp38-cp38-macosx_10_9_x86_64.whl (490 kB)\n",
      "\u001b[K     |████████████████████████████████| 490 kB 35.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.4.1-py3-none-any.whl (182 kB)\n",
      "\u001b[K     |████████████████████████████████| 182 kB 70.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.3.0,>=8.2.2\n",
      "  Downloading thinc-8.2.5.tar.gz (193 kB)\n",
      "\u001b[K     |████████████████████████████████| 193 kB 38.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.20.2)\n",
      "Collecting language-data>=1.2\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4 MB 69.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting marisa-trie>=1.1.0\n",
      "  Downloading marisa_trie-1.2.1-cp38-cp38-macosx_10_9_x86_64.whl (192 kB)\n",
      "\u001b[K     |████████████████████████████████| 192 kB 40.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.11-cp38-cp38-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Collecting shellingham>=1.3.0\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloudpathlib<1.0.0,>=0.7.0\n",
      "  Downloading cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open<8.0.0,>=5.2.1\n",
      "  Downloading smart_open-7.3.0-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting wrapt\n",
      "  Downloading wrapt-1.17.2-cp38-cp38-macosx_10_9_x86_64.whl (38 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Building wheels for collected packages: preshed, thinc\n",
      "  Building wheel for preshed (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for preshed: filename=preshed-3.0.10-cp38-cp38-macosx_10_9_x86_64.whl size=141786 sha256=eaa4d0dca6483585eb2a2522e6b343021f9a97250b39d570dae280925793c210\n",
      "  Stored in directory: /Users/viraajimothukuri/Library/Caches/pip/wheels/93/47/a4/a942173418f385cbbae450dcb851ea93cd45faaeb83cb51d4f\n",
      "  Building wheel for thinc (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for thinc: filename=thinc-8.2.5-cp38-cp38-macosx_10_9_x86_64.whl size=861746 sha256=fa8348766a6761b400da52b480663f1838fd3ba620a8ff9485de4db1e6125570\n",
      "  Stored in directory: /Users/viraajimothukuri/Library/Caches/pip/wheels/ca/65/2f/a856a5c5a2338dcc54a8e8fbbd904aef94510ff7575effd769\n",
      "Successfully built preshed thinc\n",
      "Installing collected packages: catalogue, wrapt, srsly, shellingham, murmurhash, marisa-trie, cymem, wasabi, typer, smart-open, preshed, language-data, confection, cloudpathlib, blis, weasel, thinc, spacy-loggers, spacy-legacy, langcodes, spacy, nltk\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.20.0 confection-0.1.5 cymem-2.0.11 langcodes-3.4.1 language-data-1.3.0 marisa-trie-1.2.1 murmurhash-1.0.13 nltk-3.9.1 preshed-3.0.10 shellingham-1.5.4 smart-open-7.3.0 spacy-3.7.5 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.5 typer-0.16.0 wasabi-1.1.3 weasel-0.4.1 wrapt-1.17.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.8/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy pandas matplotlib seaborn nltk spacy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T14:51:28.776049Z",
     "start_time": "2025-07-02T14:51:02.726857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\r\n",
      "  Using cached numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl.metadata (5.6 kB)\r\n",
      "Collecting pandas\r\n",
      "  Using cached pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl.metadata (18 kB)\r\n",
      "Collecting matplotlib\r\n",
      "  Using cached matplotlib-3.7.5-cp38-cp38-macosx_10_12_x86_64.whl.metadata (5.7 kB)\r\n",
      "Collecting seaborn\r\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\r\n",
      "Collecting nltk\r\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting spacy\r\n",
      "  Using cached spacy-3.8.2.tar.gz (1.3 MB)\r\n",
      "  Installing build dependencies ... \u001b[?25lerror\r\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[79 lines of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\r\n",
      "  \u001b[31m   \u001b[0m Collecting setuptools\r\n",
      "  \u001b[31m   \u001b[0m   Using cached setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "  \u001b[31m   \u001b[0m Collecting cython<3.0,>=0.25\r\n",
      "  \u001b[31m   \u001b[0m   Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\r\n",
      "  \u001b[31m   \u001b[0m Collecting cymem<2.1.0,>=2.0.2\r\n",
      "  \u001b[31m   \u001b[0m   Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\r\n",
      "  \u001b[31m   \u001b[0m Collecting preshed<3.1.0,>=3.0.2\r\n",
      "  \u001b[31m   \u001b[0m   Using cached preshed-3.0.10.tar.gz (15 kB)\r\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\r\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\r\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\r\n",
      "  \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\r\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\r\n",
      "  \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\r\n",
      "  \u001b[31m   \u001b[0m Collecting murmurhash<1.1.0,>=0.28.0\r\n",
      "  \u001b[31m   \u001b[0m   Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\r\n",
      "  \u001b[31m   \u001b[0m Collecting thinc<8.4.0,>=8.3.0\r\n",
      "  \u001b[31m   \u001b[0m   Using cached thinc-8.3.2.tar.gz (193 kB)\r\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: started\r\n",
      "  \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'error'\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[43 lines of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting setuptools\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting cython<3.0,>=0.25\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached Cython-0.29.37-py2.py3-none-any.whl.metadata (3.1 kB)\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting murmurhash<1.1.0,>=1.0.2\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached murmurhash-1.0.13-cp38-cp38-macosx_10_9_x86_64.whl\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting cymem<2.1.0,>=2.0.2\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached cymem-2.0.11-cp38-cp38-macosx_10_9_x86_64.whl\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting preshed<3.1.0,>=3.0.2\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached preshed-3.0.10.tar.gz (15 kB)\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: started\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'done'\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Getting requirements to build wheel: started\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Getting requirements to build wheel: finished with status 'done'\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): started\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Preparing metadata (pyproject.toml): finished with status 'done'\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting blis<1.1.0,>=1.0.0\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached blis-1.0.2.tar.gz (3.6 MB)\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: started\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Installing build dependencies: finished with status 'error'\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m╰─>\u001b[0m \u001b[31m[7 lines of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting setuptools\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached setuptools-75.3.2-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m Collecting cython>=0.25\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   Using cached cython-3.1.2-cp38-cp38-macosx_10_9_x86_64.whl.metadata (5.6 kB)\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31mERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4)\u001b[0m\u001b[31m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[0m\u001b[31mERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\u001b[0m\u001b[31m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "  \u001b[31m   \u001b[0m   \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m   \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "  \u001b[31m   \u001b[0m \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "  \u001b[31m   \u001b[0m \r\n",
      "  \u001b[31m   \u001b[0m \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\r\n",
      "  \r\n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m \u001b[32mpip subprocess to install build dependencies\u001b[0m did not run successfully.\r\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\r\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install numpy pandas matplotlib seaborn nltk spacy scikit-learn tqdm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Download spaCy English model if not present\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     spacy\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men_core_web_sm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download spaCy English model if not present\n",
    "import spacy\n",
    "try:\n",
    "    spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstring\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01municodedata\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk_downloads = ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger', 'maxent_ne_chunker', 'words']\n",
    "for item in nltk_downloads:\n",
    "    try:\n",
    "        nltk.download(item, quiet=True)\n",
    "    except:\n",
    "        print(f\"Could not download {item}\")\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"spaCy English model not found. Install with: python -m spacy download en_core_web_sm\")\n",
    "    nlp = None\n",
    "\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create diverse sample texts for preprocessing\n",
    "sample_texts = {\n",
    "    'social_media': [\n",
    "        \"OMG!!! This is AMAZING 😍😍😍 #bestday #excited @john_doe https://example.com/photo\",\n",
    "        \"Can't believe it's already 2023... time flies so fast! 🕐 RT if you agree 👍\",\n",
    "        \"Working from home again 😴 Coffee ☕ is my best friend today #WFH #Monday\"\n",
    "    ],\n",
    "    'emails': [\n",
    "        \"Dear Mr. Smith,\\n\\nI hope this email finds you well. I am writing to discuss...\",\n",
    "        \"Hi there!\\n\\nThanks for your email. Please find attached the document you requested.\",\n",
    "        \"Subject: Re: Meeting Tomorrow\\n\\nHi team,\\n\\nLet's reschedule to 3 PM EST.\"\n",
    "    ],\n",
    "    'news': [\n",
    "        \"Breaking: The stock market reached an all-time high today, with tech stocks leading the surge.\",\n",
    "        \"Scientists discover new species in the Amazon rainforest, highlighting biodiversity importance.\",\n",
    "        \"Local weather update: Expect thunderstorms this afternoon with temperatures around 75°F.\"\n",
    "    ],\n",
    "    'reviews': [\n",
    "        \"This product is absolutely terrible!!! Don't waste your money. 1/5 stars ⭐\",\n",
    "        \"Pretty good overall, but could be better. The delivery was fast though. 4/5\",\n",
    "        \"BEST PURCHASE EVER! Highly recommend to everyone!!! 5 stars ⭐⭐⭐⭐⭐\"\n",
    "    ],\n",
    "    'technical': [\n",
    "        \"The API endpoint returns JSON data with user_id, timestamp, and status_code fields.\",\n",
    "        \"To install the package, run: pip install numpy==1.21.0 --user\",\n",
    "        \"Error 404: Page not found. Check the URL: https://api.example.com/v1/users\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Combine all texts for analysis\n",
    "all_texts = []\n",
    "text_labels = []\n",
    "for category, texts in sample_texts.items():\n",
    "    all_texts.extend(texts)\n",
    "    text_labels.extend([category] * len(texts))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': all_texts,\n",
    "    'category': text_labels\n",
    "})\n",
    "\n",
    "print(f\"Created dataset with {len(df)} text samples across {len(sample_texts)} categories\")\n",
    "print(\"\\nCategory distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "\n",
    "# Display sample texts\n",
    "print(\"\\nSample texts:\")\n",
    "for i, row in df.head().iterrows():\n",
    "    print(f\"{row['category']}: {row['text'][:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicTextCleaner:\n",
    "    \"\"\"Basic text cleaning operations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
    "        self.email_pattern = re.compile(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b')\n",
    "        self.mention_pattern = re.compile(r'@\\w+')\n",
    "        self.hashtag_pattern = re.compile(r'#\\w+')\n",
    "        self.phone_pattern = re.compile(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b')\n",
    "    \n",
    "    def remove_urls(self, text):\n",
    "        \"\"\"Remove URLs from text\"\"\"\n",
    "        return self.url_pattern.sub('', text)\n",
    "    \n",
    "    def remove_emails(self, text):\n",
    "        \"\"\"Remove email addresses from text\"\"\"\n",
    "        return self.email_pattern.sub('', text)\n",
    "    \n",
    "    def remove_mentions(self, text):\n",
    "        \"\"\"Remove social media mentions (@username)\"\"\"\n",
    "        return self.mention_pattern.sub('', text)\n",
    "    \n",
    "    def remove_hashtags(self, text):\n",
    "        \"\"\"Remove hashtags from text\"\"\"\n",
    "        return self.hashtag_pattern.sub('', text)\n",
    "    \n",
    "    def remove_phone_numbers(self, text):\n",
    "        \"\"\"Remove phone numbers from text\"\"\"\n",
    "        return self.phone_pattern.sub('', text)\n",
    "    \n",
    "    def remove_extra_whitespace(self, text):\n",
    "        \"\"\"Remove extra whitespace and normalize\"\"\"\n",
    "        # Replace multiple whitespace with single space\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    \n",
    "    def remove_special_characters(self, text, keep_alphanumeric=True):\n",
    "        \"\"\"Remove special characters\"\"\"\n",
    "        if keep_alphanumeric:\n",
    "            # Keep letters, numbers, and spaces\n",
    "            text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "        else:\n",
    "            # Keep only letters and spaces\n",
    "            text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        return text\n",
    "    \n",
    "    def to_lowercase(self, text):\n",
    "        \"\"\"Convert text to lowercase\"\"\"\n",
    "        return text.lower()\n",
    "    \n",
    "    def basic_clean(self, text):\n",
    "        \"\"\"Apply basic cleaning pipeline\"\"\"\n",
    "        text = self.remove_urls(text)\n",
    "        text = self.remove_emails(text)\n",
    "        text = self.remove_extra_whitespace(text)\n",
    "        text = self.to_lowercase(text)\n",
    "        return text\n",
    "\n",
    "# Test basic cleaning\n",
    "cleaner = BasicTextCleaner()\n",
    "\n",
    "print(\"Basic Text Cleaning Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, texts in sample_texts.items():\n",
    "    print(f\"\\n{category.upper()}:\")\n",
    "    for text in texts[:1]:  # Show first example from each category\n",
    "        print(f\"Original: {text}\")\n",
    "        cleaned = cleaner.basic_clean(text)\n",
    "        print(f\"Cleaned:  {cleaned}\")\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTextCleaner(BasicTextCleaner):\n",
    "    \"\"\"Advanced text cleaning with Unicode and encoding handling\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.emoji_pattern = re.compile(\n",
    "            \"[\"\n",
    "            \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            \"\\U00002702-\\U000027B0\"\n",
    "            \"\\U000024C2-\\U0001F251\"\n",
    "            \"]+\", flags=re.UNICODE\n",
    "        )\n",
    "    \n",
    "    def normalize_unicode(self, text):\n",
    "        \"\"\"Normalize Unicode characters\"\"\"\n",
    "        # Normalize to NFKD form (canonical decomposition)\n",
    "        text = unicodedata.normalize('NFKD', text)\n",
    "        # Remove combining characters\n",
    "        text = ''.join(c for c in text if not unicodedata.combining(c))\n",
    "        return text\n",
    "    \n",
    "    def remove_emojis(self, text):\n",
    "        \"\"\"Remove emoji characters\"\"\"\n",
    "        return self.emoji_pattern.sub('', text)\n",
    "    \n",
    "    def expand_contractions(self, text):\n",
    "        \"\"\"Expand common English contractions\"\"\"\n",
    "        contractions = {\n",
    "            \"can't\": \"cannot\",\n",
    "            \"won't\": \"will not\",\n",
    "            \"n't\": \" not\",\n",
    "            \"'re\": \" are\",\n",
    "            \"'ve\": \" have\",\n",
    "            \"'ll\": \" will\",\n",
    "            \"'d\": \" would\",\n",
    "            \"'m\": \" am\",\n",
    "            \"'s\": \" is\"\n",
    "        }\n",
    "        \n",
    "        for contraction, expansion in contractions.items():\n",
    "            text = text.replace(contraction, expansion)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def handle_repetitions(self, text, max_repeat=2):\n",
    "        \"\"\"Handle character repetitions (e.g., 'sooo' -> 'so')\"\"\"\n",
    "        pattern = r'(.)\\1{' + str(max_repeat) + ',}'\n",
    "        return re.sub(pattern, r'\\1' * max_repeat, text)\n",
    "    \n",
    "    def remove_html_tags(self, text):\n",
    "        \"\"\"Remove HTML tags from text\"\"\"\n",
    "        html_pattern = re.compile(r'<.*?>')\n",
    "        return html_pattern.sub('', text)\n",
    "    \n",
    "    def normalize_numbers(self, text, replace_with='<NUM>'):\n",
    "        \"\"\"Replace numbers with placeholder\"\"\"\n",
    "        # Match integers and floats\n",
    "        number_pattern = r'\\b\\d+(?:\\.\\d+)?\\b'\n",
    "        return re.sub(number_pattern, replace_with, text)\n",
    "    \n",
    "    def advanced_clean(self, text):\n",
    "        \"\"\"Apply advanced cleaning pipeline\"\"\"\n",
    "        text = self.normalize_unicode(text)\n",
    "        text = self.remove_html_tags(text)\n",
    "        text = self.expand_contractions(text)\n",
    "        text = self.remove_emojis(text)\n",
    "        text = self.remove_urls(text)\n",
    "        text = self.remove_emails(text)\n",
    "        text = self.remove_mentions(text)\n",
    "        text = self.remove_hashtags(text)\n",
    "        text = self.handle_repetitions(text)\n",
    "        text = self.remove_extra_whitespace(text)\n",
    "        text = self.to_lowercase(text)\n",
    "        return text\n",
    "\n",
    "# Test advanced cleaning\n",
    "advanced_cleaner = AdvancedTextCleaner()\n",
    "\n",
    "print(\"Advanced Text Cleaning Examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_texts = [\n",
    "    \"OMG!!! This is AMAZING 😍😍😍 #bestday can't believe it!!!\",\n",
    "    \"Check this out: https://example.com @john_doe 🔥🔥\",\n",
    "    \"I'm sooooo excited!!! Won't you join us? 💯\",\n",
    "    \"<p>HTML content with <strong>tags</strong></p>\",\n",
    "    \"Numbers: 123, 45.67, and $89.99 are here\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    print(f\"Original: {text}\")\n",
    "    cleaned = advanced_cleaner.advanced_clean(text)\n",
    "    print(f\"Cleaned:  {cleaned}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tokenization Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizationTools:\n",
    "    \"\"\"Various tokenization strategies\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def simple_tokenize(self, text):\n",
    "        \"\"\"Simple whitespace tokenization\"\"\"\n",
    "        return text.split()\n",
    "    \n",
    "    def nltk_word_tokenize(self, text):\n",
    "        \"\"\"NLTK word tokenization\"\"\"\n",
    "        return word_tokenize(text)\n",
    "    \n",
    "    def regex_tokenize(self, text, pattern=r'\\b\\w+\\b'):\n",
    "        \"\"\"Regex-based tokenization\"\"\"\n",
    "        return re.findall(pattern, text)\n",
    "    \n",
    "    def sentence_tokenize(self, text):\n",
    "        \"\"\"Sentence tokenization\"\"\"\n",
    "        return sent_tokenize(text)\n",
    "    \n",
    "    def spacy_tokenize(self, text):\n",
    "        \"\"\"spaCy tokenization\"\"\"\n",
    "        if nlp is None:\n",
    "            return self.nltk_word_tokenize(text)\n",
    "        doc = nlp(text)\n",
    "        return [token.text for token in doc]\n",
    "    \n",
    "    def custom_tokenize(self, text, preserve_case=False, min_length=1):\n",
    "        \"\"\"Custom tokenization with options\"\"\"\n",
    "        # Split on whitespace and punctuation\n",
    "        tokens = re.findall(r'\\b\\w+\\b', text)\n",
    "        \n",
    "        if not preserve_case:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        \n",
    "        # Filter by minimum length\n",
    "        tokens = [token for token in tokens if len(token) >= min_length]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def subword_tokenize(self, text, max_subword_length=6):\n",
    "        \"\"\"Simple subword tokenization (character n-grams)\"\"\"\n",
    "        words = self.simple_tokenize(text)\n",
    "        subwords = []\n",
    "        \n",
    "        for word in words:\n",
    "            if len(word) <= max_subword_length:\n",
    "                subwords.append(word)\n",
    "            else:\n",
    "                # Split into overlapping subwords\n",
    "                for i in range(len(word) - max_subword_length + 1):\n",
    "                    subwords.append(word[i:i + max_subword_length])\n",
    "        \n",
    "        return subwords\n",
    "    \n",
    "    def compare_tokenizers(self, text):\n",
    "        \"\"\"Compare different tokenization methods\"\"\"\n",
    "        methods = {\n",
    "            'Simple': self.simple_tokenize,\n",
    "            'NLTK': self.nltk_word_tokenize,\n",
    "            'Regex': self.regex_tokenize,\n",
    "            'spaCy': self.spacy_tokenize,\n",
    "            'Custom': self.custom_tokenize\n",
    "        }\n",
    "        \n",
    "        results = {}\n",
    "        for name, method in methods.items():\n",
    "            try:\n",
    "                tokens = method(text)\n",
    "                results[name] = tokens\n",
    "            except Exception as e:\n",
    "                results[name] = f\"Error: {e}\"\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test tokenization\n",
    "tokenizer = TokenizationTools()\n",
    "\n",
    "test_text = \"Hello, world! This is a test sentence with punctuation... How does it work?\"\n",
    "\n",
    "print(\"Tokenization Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text: {test_text}\")\n",
    "print()\n",
    "\n",
    "results = tokenizer.compare_tokenizers(test_text)\n",
    "for method, tokens in results.items():\n",
    "    if isinstance(tokens, list):\n",
    "        print(f\"{method:8}: {tokens} ({len(tokens)} tokens)\")\n",
    "    else:\n",
    "        print(f\"{method:8}: {tokens}\")\n",
    "\n",
    "# Test sentence tokenization\n",
    "long_text = \"Hello world. This is the first sentence! Is this the second? Yes, it is.\"\n",
    "sentences = tokenizer.sentence_tokenize(long_text)\n",
    "print(f\"\\nSentence tokenization:\")\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"{i}. {sent}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer:\n",
    "    \"\"\"Text normalization including stemming and lemmatization\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.porter_stemmer = PorterStemmer()\n",
    "        self.snowball_stemmer = SnowballStemmer('english')\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    def stem_porter(self, tokens):\n",
    "        \"\"\"Apply Porter stemming\"\"\"\n",
    "        return [self.porter_stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    def stem_snowball(self, tokens):\n",
    "        \"\"\"Apply Snowball stemming\"\"\"\n",
    "        return [self.snowball_stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    def lemmatize(self, tokens, pos_tags=None):\n",
    "        \"\"\"Apply lemmatization with optional POS tags\"\"\"\n",
    "        if pos_tags is None:\n",
    "            return [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        else:\n",
    "            lemmatized = []\n",
    "            for token, pos in zip(tokens, pos_tags):\n",
    "                # Convert POS tag to WordNet format\n",
    "                wordnet_pos = self._get_wordnet_pos(pos)\n",
    "                lemmatized.append(self.lemmatizer.lemmatize(token, wordnet_pos))\n",
    "            return lemmatized\n",
    "    \n",
    "    def _get_wordnet_pos(self, pos_tag):\n",
    "        \"\"\"Convert NLTK POS tag to WordNet POS tag\"\"\"\n",
    "        if pos_tag.startswith('J'):\n",
    "            return 'a'  # adjective\n",
    "        elif pos_tag.startswith('V'):\n",
    "            return 'v'  # verb\n",
    "        elif pos_tag.startswith('N'):\n",
    "            return 'n'  # noun\n",
    "        elif pos_tag.startswith('R'):\n",
    "            return 'r'  # adverb\n",
    "        else:\n",
    "            return 'n'  # default to noun\n",
    "    \n",
    "    def remove_stopwords(self, tokens, custom_stopwords=None):\n",
    "        \"\"\"Remove stopwords\"\"\"\n",
    "        stopwords_set = self.stop_words\n",
    "        if custom_stopwords:\n",
    "            stopwords_set = stopwords_set.union(set(custom_stopwords))\n",
    "        \n",
    "        return [token for token in tokens if token.lower() not in stopwords_set]\n",
    "    \n",
    "    def normalize_tokens(self, tokens, method='lemma', remove_stops=True, pos_tags=None):\n",
    "        \"\"\"Normalize tokens using specified method\"\"\"\n",
    "        # Remove stopwords first if requested\n",
    "        if remove_stops:\n",
    "            tokens = self.remove_stopwords(tokens)\n",
    "        \n",
    "        # Apply normalization method\n",
    "        if method == 'porter':\n",
    "            return self.stem_porter(tokens)\n",
    "        elif method == 'snowball':\n",
    "            return self.stem_snowball(tokens)\n",
    "        elif method == 'lemma':\n",
    "            return self.lemmatize(tokens, pos_tags)\n",
    "        else:\n",
    "            return tokens\n",
    "    \n",
    "    def compare_normalization(self, text):\n",
    "        \"\"\"Compare different normalization methods\"\"\"\n",
    "        # Tokenize text\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        \n",
    "        # Get POS tags for better lemmatization\n",
    "        pos_tags = [tag for word, tag in pos_tag(tokens)]\n",
    "        \n",
    "        results = {\n",
    "            'Original': tokens,\n",
    "            'Porter Stem': self.stem_porter(tokens),\n",
    "            'Snowball Stem': self.stem_snowball(tokens),\n",
    "            'Lemmatized': self.lemmatize(tokens, pos_tags),\n",
    "            'No Stopwords': self.remove_stopwords(tokens)\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Test normalization\n",
    "normalizer = TextNormalizer()\n",
    "\n",
    "test_text = \"The cats were running and jumping over the fences quickly.\"\n",
    "\n",
    "print(\"Text Normalization Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Text: {test_text}\")\n",
    "print()\n",
    "\n",
    "results = normalizer.compare_normalization(test_text)\n",
    "for method, tokens in results.items():\n",
    "    print(f\"{method:15}: {tokens}\")\n",
    "\n",
    "# Test with more complex examples\n",
    "complex_examples = [\n",
    "    \"The children were happily playing with their toys.\",\n",
    "    \"He has been studying and learning new techniques.\",\n",
    "    \"The best restaurants are serving delicious meals.\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEMMING vs LEMMATIZATION COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for text in complex_examples:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    # Remove non-alphabetic tokens\n",
    "    tokens = [t for t in tokens if t.isalpha()]\n",
    "    \n",
    "    pos_tags = [tag for word, tag in pos_tag(tokens)]\n",
    "    \n",
    "    print(f\"\\nOriginal:  {' '.join(tokens)}\")\n",
    "    print(f\"Porter:    {' '.join(normalizer.stem_porter(tokens))}\")\n",
    "    print(f\"Snowball:  {' '.join(normalizer.stem_snowball(tokens))}\")\n",
    "    print(f\"Lemmatized: {' '.join(normalizer.lemmatize(tokens, pos_tags))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comprehensive Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessingPipeline:\n",
    "    \"\"\"Complete text preprocessing pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        self.cleaner = AdvancedTextCleaner()\n",
    "        self.tokenizer = TokenizationTools()\n",
    "        self.normalizer = TextNormalizer()\n",
    "        \n",
    "        # Default configuration\n",
    "        self.config = {\n",
    "            'lowercase': True,\n",
    "            'remove_urls': True,\n",
    "            'remove_emails': True,\n",
    "            'remove_mentions': True,\n",
    "            'remove_hashtags': True,\n",
    "            'remove_emojis': True,\n",
    "            'expand_contractions': True,\n",
    "            'remove_html': True,\n",
    "            'normalize_unicode': True,\n",
    "            'handle_repetitions': True,\n",
    "            'tokenization_method': 'nltk',  # 'simple', 'nltk', 'spacy', 'custom'\n",
    "            'normalization_method': 'lemma',  # 'none', 'porter', 'snowball', 'lemma'\n",
    "            'remove_stopwords': True,\n",
    "            'min_token_length': 2,\n",
    "            'max_token_length': 50,\n",
    "            'remove_digits': False,\n",
    "            'remove_punctuation': True\n",
    "        }\n",
    "        \n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"Apply text cleaning based on configuration\"\"\"\n",
    "        if self.config['normalize_unicode']:\n",
    "            text = self.cleaner.normalize_unicode(text)\n",
    "        \n",
    "        if self.config['remove_html']:\n",
    "            text = self.cleaner.remove_html_tags(text)\n",
    "        \n",
    "        if self.config['expand_contractions']:\n",
    "            text = self.cleaner.expand_contractions(text)\n",
    "        \n",
    "        if self.config['remove_emojis']:\n",
    "            text = self.cleaner.remove_emojis(text)\n",
    "        \n",
    "        if self.config['remove_urls']:\n",
    "            text = self.cleaner.remove_urls(text)\n",
    "        \n",
    "        if self.config['remove_emails']:\n",
    "            text = self.cleaner.remove_emails(text)\n",
    "        \n",
    "        if self.config['remove_mentions']:\n",
    "            text = self.cleaner.remove_mentions(text)\n",
    "        \n",
    "        if self.config['remove_hashtags']:\n",
    "            text = self.cleaner.remove_hashtags(text)\n",
    "        \n",
    "        if self.config['handle_repetitions']:\n",
    "            text = self.cleaner.handle_repetitions(text)\n",
    "        \n",
    "        if self.config['lowercase']:\n",
    "            text = text.lower()\n",
    "        \n",
    "        text = self.cleaner.remove_extra_whitespace(text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize_text(self, text):\n",
    "        \"\"\"Tokenize text based on configuration\"\"\"\n",
    "        method = self.config['tokenization_method']\n",
    "        \n",
    "        if method == 'simple':\n",
    "            tokens = self.tokenizer.simple_tokenize(text)\n",
    "        elif method == 'nltk':\n",
    "            tokens = self.tokenizer.nltk_word_tokenize(text)\n",
    "        elif method == 'spacy':\n",
    "            tokens = self.tokenizer.spacy_tokenize(text)\n",
    "        elif method == 'custom':\n",
    "            tokens = self.tokenizer.custom_tokenize(text)\n",
    "        else:\n",
    "            tokens = self.tokenizer.nltk_word_tokenize(text)\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def filter_tokens(self, tokens):\n",
    "        \"\"\"Filter tokens based on configuration\"\"\"\n",
    "        filtered_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            # Skip empty tokens\n",
    "            if not token.strip():\n",
    "                continue\n",
    "            \n",
    "            # Length filtering\n",
    "            if len(token) < self.config['min_token_length']:\n",
    "                continue\n",
    "            if len(token) > self.config['max_token_length']:\n",
    "                continue\n",
    "            \n",
    "            # Remove digits if configured\n",
    "            if self.config['remove_digits'] and token.isdigit():\n",
    "                continue\n",
    "            \n",
    "            # Remove punctuation if configured\n",
    "            if self.config['remove_punctuation'] and token in string.punctuation:\n",
    "                continue\n",
    "            \n",
    "            # Remove non-alphabetic tokens if strict\n",
    "            if not token.isalpha() and self.config.get('alphabetic_only', False):\n",
    "                continue\n",
    "            \n",
    "            filtered_tokens.append(token)\n",
    "        \n",
    "        return filtered_tokens\n",
    "    \n",
    "    def normalize_tokens(self, tokens):\n",
    "        \"\"\"Normalize tokens based on configuration\"\"\"\n",
    "        method = self.config['normalization_method']\n",
    "        remove_stops = self.config['remove_stopwords']\n",
    "        \n",
    "        # Get POS tags if using lemmatization\n",
    "        pos_tags = None\n",
    "        if method == 'lemma':\n",
    "            pos_tags = [tag for word, tag in pos_tag(tokens)]\n",
    "        \n",
    "        return self.normalizer.normalize_tokens(tokens, method, remove_stops, pos_tags)\n",
    "    \n",
    "    def preprocess(self, text):\n",
    "        \"\"\"Complete preprocessing pipeline\"\"\"\n",
    "        # Clean text\n",
    "        cleaned_text = self.clean_text(text)\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = self.tokenize_text(cleaned_text)\n",
    "        \n",
    "        # Filter tokens\n",
    "        filtered_tokens = self.filter_tokens(tokens)\n",
    "        \n",
    "        # Normalize tokens\n",
    "        if self.config['normalization_method'] != 'none':\n",
    "            normalized_tokens = self.normalize_tokens(filtered_tokens)\n",
    "        else:\n",
    "            normalized_tokens = filtered_tokens\n",
    "        \n",
    "        return normalized_tokens\n",
    "    \n",
    "    def preprocess_batch(self, texts):\n",
    "        \"\"\"Preprocess a batch of texts\"\"\"\n",
    "        return [self.preprocess(text) for text in texts]\n",
    "    \n",
    "    def get_stats(self, original_texts, processed_tokens):\n",
    "        \"\"\"Get preprocessing statistics\"\"\"\n",
    "        stats = {\n",
    "            'total_texts': len(original_texts),\n",
    "            'avg_original_length': np.mean([len(text) for text in original_texts]),\n",
    "            'avg_tokens_per_text': np.mean([len(tokens) for tokens in processed_tokens]),\n",
    "            'total_tokens': sum(len(tokens) for tokens in processed_tokens),\n",
    "            'unique_tokens': len(set(token for tokens in processed_tokens for token in tokens))\n",
    "        }\n",
    "        return stats\n",
    "\n",
    "# Test the complete pipeline\n",
    "print(\"Complete Preprocessing Pipeline Test:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test with different configurations\n",
    "configs = {\n",
    "    'basic': {\n",
    "        'normalization_method': 'none',\n",
    "        'remove_stopwords': False\n",
    "    },\n",
    "    'standard': {\n",
    "        'normalization_method': 'lemma',\n",
    "        'remove_stopwords': True\n",
    "    },\n",
    "    'aggressive': {\n",
    "        'normalization_method': 'porter',\n",
    "        'remove_stopwords': True,\n",
    "        'min_token_length': 3,\n",
    "        'alphabetic_only': True\n",
    "    }\n",
    "}\n",
    "\n",
    "test_text = \"OMG!!! I can't believe this is happening 😍 Check out https://example.com @username #amazing\"\n",
    "\n",
    "for config_name, config in configs.items():\n",
    "    pipeline = TextPreprocessingPipeline(config)\n",
    "    result = pipeline.preprocess(test_text)\n",
    "    \n",
    "    print(f\"\\n{config_name.upper()} CONFIG:\")\n",
    "    print(f\"Original: {test_text}\")\n",
    "    print(f\"Result:   {result}\")\n",
    "    print(f\"Tokens:   {len(result)}\")\n",
    "\n",
    "# Test with all sample texts\n",
    "standard_pipeline = TextPreprocessingPipeline()\n",
    "all_processed = standard_pipeline.preprocess_batch(all_texts)\n",
    "stats = standard_pipeline.get_stats(all_texts, all_processed)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BATCH PROCESSING STATISTICS\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key:20}: {value:.2f}\" if isinstance(value, float) else f\"{key:20}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preprocessing Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_preprocessing_impact(texts, pipeline_configs):\n",
    "    \"\"\"Analyze the impact of different preprocessing configurations\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for config_name, config in pipeline_configs.items():\n",
    "        pipeline = TextPreprocessingPipeline(config)\n",
    "        processed = pipeline.preprocess_batch(texts)\n",
    "        stats = pipeline.get_stats(texts, processed)\n",
    "        \n",
    "        results[config_name] = {\n",
    "            'processed_texts': processed,\n",
    "            'stats': stats,\n",
    "            'vocab': set(token for tokens in processed for token in tokens)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_preprocessing_comparison(analysis_results):\n",
    "    \"\"\"Visualize preprocessing comparison\"\"\"\n",
    "    configs = list(analysis_results.keys())\n",
    "    \n",
    "    # Extract metrics for comparison\n",
    "    metrics = {\n",
    "        'avg_tokens': [analysis_results[config]['stats']['avg_tokens_per_text'] for config in configs],\n",
    "        'vocab_size': [len(analysis_results[config]['vocab']) for config in configs],\n",
    "        'total_tokens': [analysis_results[config]['stats']['total_tokens'] for config in configs]\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Average tokens per text\n",
    "    axes[0, 0].bar(configs, metrics['avg_tokens'])\n",
    "    axes[0, 0].set_title('Average Tokens per Text')\n",
    "    axes[0, 0].set_ylabel('Number of Tokens')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Vocabulary size\n",
    "    axes[0, 1].bar(configs, metrics['vocab_size'])\n",
    "    axes[0, 1].set_title('Vocabulary Size')\n",
    "    axes[0, 1].set_ylabel('Unique Tokens')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Total tokens\n",
    "    axes[1, 0].bar(configs, metrics['total_tokens'])\n",
    "    axes[1, 0].set_title('Total Tokens')\n",
    "    axes[1, 0].set_ylabel('Number of Tokens')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Token length distribution for first config\n",
    "    first_config = configs[0]\n",
    "    all_tokens = [token for tokens in analysis_results[first_config]['processed_texts'] for token in tokens]\n",
    "    token_lengths = [len(token) for token in all_tokens]\n",
    "    \n",
    "    axes[1, 1].hist(token_lengths, bins=range(1, max(token_lengths) + 2), alpha=0.7)\n",
    "    axes[1, 1].set_title(f'Token Length Distribution ({first_config})')\n",
    "    axes[1, 1].set_xlabel('Token Length')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Test preprocessing configurations\n",
    "test_configs = {\n",
    "    'minimal': {\n",
    "        'lowercase': True,\n",
    "        'normalization_method': 'none',\n",
    "        'remove_stopwords': False,\n",
    "        'remove_punctuation': False\n",
    "    },\n",
    "    'standard': {\n",
    "        'normalization_method': 'lemma',\n",
    "        'remove_stopwords': True\n",
    "    },\n",
    "    'aggressive': {\n",
    "        'normalization_method': 'porter',\n",
    "        'remove_stopwords': True,\n",
    "        'min_token_length': 3,\n",
    "        'alphabetic_only': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Analyze preprocessing impact\n",
    "analysis_results = analyze_preprocessing_impact(all_texts, test_configs)\n",
    "\n",
    "# Visualize results\n",
    "metrics = visualize_preprocessing_comparison(analysis_results)\n",
    "\n",
    "# Print detailed comparison\n",
    "print(\"\\nDetailed Preprocessing Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for config_name in test_configs.keys():\n",
    "    stats = analysis_results[config_name]['stats']\n",
    "    vocab_size = len(analysis_results[config_name]['vocab'])\n",
    "    \n",
    "    print(f\"\\n{config_name.upper()} CONFIGURATION:\")\n",
    "    print(f\"  Average tokens per text: {stats['avg_tokens_per_text']:.2f}\")\n",
    "    print(f\"  Total tokens: {stats['total_tokens']}\")\n",
    "    print(f\"  Vocabulary size: {vocab_size}\")\n",
    "    print(f\"  Vocabulary/Total ratio: {vocab_size/stats['total_tokens']:.3f}\")\n",
    "\n",
    "# Show sample processed texts\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAMPLE PROCESSED TEXTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sample_idx = 0\n",
    "original_text = all_texts[sample_idx]\n",
    "print(f\"Original: {original_text}\")\n",
    "\n",
    "for config_name in test_configs.keys():\n",
    "    processed = analysis_results[config_name]['processed_texts'][sample_idx]\n",
    "    print(f\"{config_name:10}: {' '.join(processed)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Challenge Section\n",
    "\n",
    "Complete these challenges to master text preprocessing techniques!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Custom Stopword List\n",
    "\n",
    "Create a domain-specific stopword list for social media text.\n",
    "\n",
    "**Tasks:**\n",
    "1. Identify common social media terms that should be removed\n",
    "2. Implement a custom stopword remover\n",
    "3. Compare with standard English stopwords\n",
    "4. Test on social media sample texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement custom stopword list for social media\n",
    "def create_social_media_stopwords():\n",
    "    \"\"\"\n",
    "    Create a custom stopword list for social media text\n",
    "    Include: common abbreviations, filler words, platform-specific terms\n",
    "    \"\"\"\n",
    "    social_stopwords = [\n",
    "        # Your implementation here\n",
    "        # Add common social media terms, abbreviations, etc.\n",
    "    ]\n",
    "    return social_stopwords\n",
    "\n",
    "def test_custom_stopwords():\n",
    "    # Test your implementation\n",
    "    social_texts = sample_texts['social_media']\n",
    "    # Your testing code here\n",
    "    pass\n",
    "\n",
    "# test_custom_stopwords()\n",
    "print(\"Challenge L1: Implement custom stopword creation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Regex Pattern Matching\n",
    "\n",
    "Create regex patterns to identify and extract specific text patterns.\n",
    "\n",
    "**Tasks:**\n",
    "1. Write regex to extract dates in various formats\n",
    "2. Create pattern for extracting currency amounts\n",
    "3. Build regex for identifying product codes (e.g., ABC-123)\n",
    "4. Test patterns on mixed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement regex pattern extractors\n",
    "class PatternExtractor:\n",
    "    def __init__(self):\n",
    "        # Define your regex patterns here\n",
    "        self.date_pattern = None  # Match dates like 01/01/2023, Jan 1 2023, etc.\n",
    "        self.currency_pattern = None  # Match $100, €50.99, etc.\n",
    "        self.product_code_pattern = None  # Match ABC-123, XYZ123, etc.\n",
    "    \n",
    "    def extract_dates(self, text):\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def extract_currency(self, text):\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def extract_product_codes(self, text):\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "# Test patterns\n",
    "test_text = \"Order ABC-123 placed on 01/15/2023 for $99.99. Delivery by Jan 20, 2023.\"\n",
    "extractor = PatternExtractor()\n",
    "print(\"Challenge L2: Implement pattern extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Text Statistics Dashboard\n",
    "\n",
    "Create a comprehensive text statistics analyzer.\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate readability scores\n",
    "2. Analyze vocabulary richness\n",
    "3. Count sentence and paragraph statistics\n",
    "4. Create visualization dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement text statistics analyzer\n",
    "class TextStatsAnalyzer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def calculate_readability(self, text):\n",
    "        \"\"\"\n",
    "        Calculate various readability metrics:\n",
    "        - Average sentence length\n",
    "        - Average word length\n",
    "        - Syllable count estimation\n",
    "        - Flesch reading ease (if you want to implement it)\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def analyze_vocabulary(self, text):\n",
    "        \"\"\"\n",
    "        Analyze vocabulary richness:\n",
    "        - Type-token ratio\n",
    "        - Hapax legomena ratio\n",
    "        - Most frequent words\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def create_dashboard(self, text):\n",
    "        \"\"\"\n",
    "        Create a visualization dashboard\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "# analyzer = TextStatsAnalyzer()\n",
    "print(\"Challenge L3: Implement text statistics analyzer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Multilingual Text Preprocessing\n",
    "\n",
    "Extend preprocessing to handle multiple languages.\n",
    "\n",
    "**Tasks:**\n",
    "1. Implement language detection\n",
    "2. Create language-specific preprocessing rules\n",
    "3. Handle mixed-language texts\n",
    "4. Support different alphabets and scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement multilingual preprocessing\n",
    "class MultilingualPreprocessor:\n",
    "    def __init__(self):\n",
    "        # You might want to use langdetect or other libraries\n",
    "        self.supported_languages = ['en', 'es', 'fr', 'de']  # Example\n",
    "    \n",
    "    def detect_language(self, text):\n",
    "        \"\"\"\n",
    "        Detect the language of the text\n",
    "        You can implement simple heuristics or use external libraries\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def get_language_specific_stopwords(self, language):\n",
    "        \"\"\"\n",
    "        Get stopwords for specific language\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def preprocess_multilingual(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess text based on detected language\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def handle_mixed_language(self, text):\n",
    "        \"\"\"\n",
    "        Handle text with multiple languages\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "# Test with multilingual samples\n",
    "multilingual_samples = [\n",
    "    \"Hello world, this is English text.\",\n",
    "    \"Hola mundo, este es texto en español.\",\n",
    "    \"Bonjour le monde, c'est du texte français.\",\n",
    "    \"Hello, comment ça va? I'm mixing languages here.\"\n",
    "]\n",
    "\n",
    "print(\"Challenge M1: Implement multilingual preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Adaptive Preprocessing Pipeline\n",
    "\n",
    "Create a pipeline that adapts based on text characteristics.\n",
    "\n",
    "**Tasks:**\n",
    "1. Analyze text characteristics automatically\n",
    "2. Choose preprocessing steps based on analysis\n",
    "3. Implement confidence scoring for decisions\n",
    "4. Create adaptive configuration system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement adaptive preprocessing pipeline\n",
    "class AdaptivePreprocessor:\n",
    "    def __init__(self):\n",
    "        self.text_analyzers = {\n",
    "            'social_media': self._is_social_media,\n",
    "            'formal': self._is_formal,\n",
    "            'technical': self._is_technical,\n",
    "            'conversational': self._is_conversational\n",
    "        }\n",
    "    \n",
    "    def _is_social_media(self, text):\n",
    "        \"\"\"\n",
    "        Detect if text is from social media\n",
    "        Look for: hashtags, mentions, emojis, informal language\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def _is_formal(self, text):\n",
    "        \"\"\"\n",
    "        Detect formal text\n",
    "        Look for: proper grammar, longer sentences, formal vocabulary\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def _is_technical(self, text):\n",
    "        \"\"\"\n",
    "        Detect technical text\n",
    "        Look for: technical terms, code snippets, specific formatting\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def _is_conversational(self, text):\n",
    "        \"\"\"\n",
    "        Detect conversational text\n",
    "        Look for: contractions, informal language, questions\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def analyze_text_type(self, text):\n",
    "        \"\"\"\n",
    "        Analyze text and return confidence scores for each type\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def get_adaptive_config(self, text):\n",
    "        \"\"\"\n",
    "        Generate preprocessing configuration based on text analysis\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def adaptive_preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess text using adaptive configuration\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "print(\"Challenge M2: Implement adaptive preprocessing pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: Preprocessing Quality Metrics\n",
    "\n",
    "Develop metrics to evaluate preprocessing quality.\n",
    "\n",
    "**Tasks:**\n",
    "1. Create information preservation metrics\n",
    "2. Measure noise reduction effectiveness\n",
    "3. Evaluate consistency across similar texts\n",
    "4. Build automated quality assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement preprocessing quality metrics\n",
    "class PreprocessingQualityEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def information_preservation_score(self, original_text, processed_tokens):\n",
    "        \"\"\"\n",
    "        Measure how much important information is preserved\n",
    "        Consider: semantic content, named entities, key terms\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def noise_reduction_score(self, original_text, processed_tokens):\n",
    "        \"\"\"\n",
    "        Measure effectiveness of noise removal\n",
    "        Consider: removed URLs, mentions, special chars, etc.\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def consistency_score(self, similar_texts, preprocessing_func):\n",
    "        \"\"\"\n",
    "        Measure consistency of preprocessing across similar texts\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def vocabulary_quality_score(self, processed_tokens):\n",
    "        \"\"\"\n",
    "        Evaluate quality of resulting vocabulary\n",
    "        Consider: diversity, meaningfulness, coverage\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def comprehensive_evaluation(self, original_texts, processed_texts):\n",
    "        \"\"\"\n",
    "        Perform comprehensive quality evaluation\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "print(\"Challenge M3: Implement preprocessing quality metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 7: Neural Preprocessing Pipeline\n",
    "\n",
    "Implement neural network-based preprocessing components.\n",
    "\n",
    "**Tasks:**\n",
    "1. Train neural tokenizer using BPE or similar\n",
    "2. Implement neural text normalization\n",
    "3. Create learned text cleaning rules\n",
    "4. Build end-to-end neural preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement neural preprocessing components\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class NeuralTokenizer:\n",
    "    def __init__(self, vocab_size=10000):\n",
    "        \"\"\"\n",
    "        Implement BPE (Byte Pair Encoding) or similar neural tokenization\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab = {}\n",
    "        self.merges = []\n",
    "    \n",
    "    def train(self, texts):\n",
    "        \"\"\"\n",
    "        Train the tokenizer on a corpus\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def tokenize(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize text using learned BPE\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "class NeuralTextNormalizer(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        Neural network for text normalization\n",
    "        Can learn to normalize spelling, correct typos, etc.\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "class LearnedTextCleaner:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Learn text cleaning rules from data\n",
    "        Use ML to identify what should be removed/kept\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def train_cleaning_rules(self, raw_texts, clean_texts):\n",
    "        \"\"\"\n",
    "        Learn cleaning rules from examples\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Apply learned cleaning rules\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "print(\"Challenge H1: Implement neural preprocessing pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 8: Real-time Streaming Preprocessor\n",
    "\n",
    "Build a system for real-time text preprocessing with memory constraints.\n",
    "\n",
    "**Tasks:**\n",
    "1. Implement streaming text processing\n",
    "2. Handle memory-efficient operations\n",
    "3. Create adaptive vocabulary management\n",
    "4. Build incremental learning system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement real-time streaming preprocessor\n",
    "from collections import deque\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "class StreamingPreprocessor:\n",
    "    def __init__(self, max_memory_mb=100, buffer_size=1000):\n",
    "        \"\"\"\n",
    "        Real-time text preprocessor with memory constraints\n",
    "        \"\"\"\n",
    "        self.max_memory_mb = max_memory_mb\n",
    "        self.buffer_size = buffer_size\n",
    "        self.text_buffer = deque(maxlen=buffer_size)\n",
    "        self.vocab = {}\n",
    "        self.processing_queue = queue.Queue()\n",
    "        \n",
    "    def process_stream(self, text_stream):\n",
    "        \"\"\"\n",
    "        Process streaming text data\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def update_vocabulary_incremental(self, new_tokens):\n",
    "        \"\"\"\n",
    "        Update vocabulary incrementally with memory management\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def memory_efficient_preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess text with minimal memory usage\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def adaptive_vocab_pruning(self):\n",
    "        \"\"\"\n",
    "        Prune vocabulary based on usage patterns\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "class IncrementalLearner:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Learn preprocessing rules incrementally\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def update_model(self, new_data):\n",
    "        \"\"\"\n",
    "        Update preprocessing model with new data\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "print(\"Challenge H2: Implement real-time streaming preprocessor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 9: Context-Aware Preprocessing\n",
    "\n",
    "Create preprocessing that considers broader context and semantics.\n",
    "\n",
    "**Tasks:**\n",
    "1. Implement context-sensitive tokenization\n",
    "2. Create semantic-aware text cleaning\n",
    "3. Build discourse-level preprocessing\n",
    "4. Develop cross-document consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement context-aware preprocessing\n",
    "class ContextAwarePreprocessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Preprocessing that considers semantic context\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def context_sensitive_tokenization(self, text, context_window=5):\n",
    "        \"\"\"\n",
    "        Tokenize based on surrounding context\n",
    "        Handle: compound words, phrasal verbs, named entities\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def semantic_text_cleaning(self, text):\n",
    "        \"\"\"\n",
    "        Clean text while preserving semantic meaning\n",
    "        Use NLP models to understand what's important\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def discourse_level_preprocessing(self, document):\n",
    "        \"\"\"\n",
    "        Preprocess considering document structure\n",
    "        Handle: coreference, discourse markers, topic coherence\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def cross_document_consistency(self, documents):\n",
    "        \"\"\"\n",
    "        Ensure consistent preprocessing across related documents\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "class SemanticAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Analyze semantic content for preprocessing decisions\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def identify_important_spans(self, text):\n",
    "        \"\"\"\n",
    "        Identify semantically important text spans\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "    \n",
    "    def measure_semantic_similarity(self, text1, text2):\n",
    "        \"\"\"\n",
    "        Measure semantic similarity between texts\n",
    "        \"\"\"\n",
    "        # Your implementation here\n",
    "        pass\n",
    "\n",
    "print(\"Challenge H3: Implement context-aware preprocessing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
